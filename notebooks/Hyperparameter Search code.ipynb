{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can use packages from parent directory\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import skorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "from monroe_data import MonroeData, MonroeDataEntry, Color # last two for reading pkl file\n",
    "import caption_featurizers\n",
    "from color_featurizers import ColorFeaturizer, color_phi_fourier\n",
    "from experiment import FeatureHandler#, evaluate_model\n",
    "import evaluation\n",
    "from models import CaptionEncoder, LiteralListener, PytorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(evaluation)\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = skorch.NeuralNet(module=CaptionEncoder, \n",
    "                       module__\n",
    "                       criterion=nn.NLLLoss, \n",
    "                       optimizer=torch.optim.Adam, \n",
    "                       lr = 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = LiteralListener(CaptionEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(ll, param_grid, refit=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"lr\":[0.001, 0.004, 0.01], 'color_hidden_size':[50, 100, 150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'color_hidden_size': 50, 'lr': 0.001},\n",
       " {'color_hidden_size': 50, 'lr': 0.004},\n",
       " {'color_hidden_size': 50, 'lr': 0.01},\n",
       " {'color_hidden_size': 100, 'lr': 0.001},\n",
       " {'color_hidden_size': 100, 'lr': 0.004},\n",
       " {'color_hidden_size': 100, 'lr': 0.01},\n",
       " {'color_hidden_size': 150, 'lr': 0.001},\n",
       " {'color_hidden_size': 150, 'lr': 0.004},\n",
       " {'color_hidden_size': 150, 'lr': 0.01}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model.logistic as lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = lr.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter maps:\n",
    "\n",
    "def init_default_arg_map(feature_handler):\n",
    "    global default_args_map\n",
    "    default_args_map = {\n",
    "        # wrappers\n",
    "        'PytorchModel': {'num_epochs' : 5,\n",
    "                       'optimizer' : torch.optim.Adam,\n",
    "                       'lr' : 0.004,\n",
    "                       'criterion': torch.nn.CrossEntropyLoss\n",
    "                      },\n",
    "        # modules\n",
    "        'CaptionEncoder': { 'embed_dim' : 100,\n",
    "                          'hidden_dim' : 100,\n",
    "                          'vocab_size' : feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                          'color_dim' : 54\n",
    "                        }\n",
    "        \n",
    "    }\n",
    "\n",
    "def fill_default_args(model, params):\n",
    "    model_default_params = {}\n",
    "    # add args that should be there and filter out args that shouldn't\n",
    "    for superclass in model.mro(): # mro = \"method resolution order - it lists all the superclasses in order\n",
    "        default_params = default_args_map.get(superclass.__name__, {})\n",
    "        model_default_params = dict(default_params, **model_default_params)\n",
    "        \n",
    "    # filter out params with keys not in default\n",
    "    params = {k: params[k] for k in params.keys() & model_default_params.keys()}\n",
    "    params = dict(model_default_params, **params)\n",
    "    \n",
    "    return params\n",
    "#     for klass in default_args_map.keys():\n",
    "#         if isinstance(model, klass):\n",
    "#             default_params = default_arg_map[klass]\n",
    "#             params = dict(default_params, **params) # extend dict\n",
    "#     return params\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model(wrapper, model, train_X, train_y, parameters):\n",
    "    wrapper_args = fill_default_args(wrapper, parameters)\n",
    "    model_args = fill_default_args(model, parameters)\n",
    "    print(wrapper_args, model_args)\n",
    "    # create new model\n",
    "    new_model = wrapper(model, **wrapper_args)\n",
    "    new_model.init_model(**model_args)\n",
    "    \n",
    "    # train model\n",
    "    new_model.fit(train_X, train_y)\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search(search_parameters, wrapper, model, feature_handler, score_model_f):\n",
    "    # ~initialization code~\n",
    "    train_X, train_y, assess_X, assess_y = feature_handler # for now, for debugging\n",
    "    \n",
    "    best_model_score = 0\n",
    "    best_model = None\n",
    "    best_model_params = None\n",
    "    tested_params = []\n",
    "\n",
    "    print(\"Searching parameter space\")\n",
    "    for parameters in search_parameters:\n",
    "        # retrain candidate model\n",
    "        candidate_model = retrain_model(wrapper, model, train_X[:100], train_y[:100], parameters)\n",
    "        # evaluate candidate model\n",
    "        print(\"Evaluating Candidate Model:\")\n",
    "        candidate_model_score = score_model_f(candidate_model, assess_X, assess_y)\n",
    "        print(\"Parameters: {}\\tScore: {}\".format(parameters, candidate_model_score))\n",
    "        # store best model, score, parameters\n",
    "        if candidate_model_score > best_model_score:\n",
    "            best_model = candidate_model\n",
    "            best_model_params = parameters\n",
    "            best_model_score = candidate_model_score\n",
    "            \n",
    "        tested_params.append((parameters, candidate_model_score))\n",
    "    \n",
    "    return best_model, best_model_params, tested_params\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(model, assess_features, assess_targets, output_to_score):\n",
    "    assess_model_outputs = model.predict(assess_features)\n",
    "    assess_model_scores = [output_to_score(assess_model_outputs[i], assess_targets[i]) for i in range(len(assess_model_outputs))]\n",
    "#     dev_data_synth_sm = copy.deepcopy(dev_data_synth)\n",
    "   # dev_data_synth_sm.data = dev_data_synth_sm.data.head(len(assess_model_scores))\n",
    "    #print(dev_data_synth_sm.data.shape)\n",
    "    reg_results = evaluation.score_model(dev_data_synth, assess_model_scores, score=evaluation.Score.COMPOSITE)\n",
    "    return reg_results[0] # just return the rho value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25850, 36)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_synth.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on literal listener:\n",
    "train_data = MonroeData(\"../data/csv/train_corpus_monroe.csv\", \"../data/entries/train_entries_monroe.pkl\")\n",
    "dev_data_synth = MonroeData(\"../data/csv/dev_corpus_synth_10fold.csv\", \"../data/entries/dev_corpus_synth_10fold.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer) # Use with parameter files that end in `endings_tkn` - using endings tokenizer to separate endings like \"ish\" and \"er\"\n",
    "color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "feature_handler = FeatureHandler(train_data, dev_data_synth, caption_phi, color_phi)\n",
    "\n",
    "output_to_score_target = lambda model_output, target: np.exp(model_output[target]) # get the model's predicted probablity at each target index and use that as the score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_default_arg_map(feature_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': torch.nn.modules.loss.CrossEntropyLoss,\n",
       " 'foobar': 4,\n",
       " 'lr': 0.004,\n",
       " 'num_epochs': 5,\n",
       " 'optimizer': torch.optim.adam.Adam}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params = {'color_dim':54}\n",
    "fill_default_args(LiteralListener, test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "literal_listener_assess_model = partial(assess_model, output_to_score=output_to_score_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function assess_model at 0x132c95c80>, output_to_score=<function <lambda> at 0x14a6a7620>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literal_listener_assess_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_default_args(LiteralListener, test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(models.LiteralListener, models.PytorchModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<class 'models.LiteralListener'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-77997b487339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdefault_args_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteralListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: <class 'models.LiteralListener'>"
     ]
    }
   ],
   "source": [
    "default_args_map[LiteralListener.mro()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"lr\":[0.001, 0.004], 'color_hidden_size':[50, 100], 'num_epochs':[1]}\n",
    "pg = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'color_hidden_size': 50, 'lr': 0.001, 'num_epochs': 1},\n",
       " {'color_hidden_size': 50, 'lr': 0.004, 'num_epochs': 1},\n",
       " {'color_hidden_size': 100, 'lr': 0.001, 'num_epochs': 1},\n",
       " {'color_hidden_size': 100, 'lr': 0.004, 'num_epochs': 1}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing data\")\n",
    "train_X = feature_handler.train_features()\n",
    "train_y = feature_handler.train_targets()\n",
    "assess_X = feature_handler.test_features()\n",
    "assess_y = feature_handler.test_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching parameter space\n",
      "{'num_epochs': 1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001, 'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>} {'embed_dim': 100, 'hidden_dim': 100, 'vocab_size': 974, 'color_dim': 54}\n",
      "---EPOCH 0---\n",
      "=========================\n",
      "AFTER EPOCH 99 - AVERAGE VALIDATION LOSS: 1.679647059449926\n",
      "=========================\n",
      "Evaluating Candidate Model:\n",
      "Parameters: {'color_hidden_size': 50, 'lr': 0.001, 'num_epochs': 1}\tScore: -0.23228980693006493\n",
      "{'num_epochs': 1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.004, 'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>} {'embed_dim': 100, 'hidden_dim': 100, 'vocab_size': 974, 'color_dim': 54}\n",
      "---EPOCH 0---\n",
      "=========================\n",
      "AFTER EPOCH 99 - AVERAGE VALIDATION LOSS: 1.8203433629265056\n",
      "=========================\n",
      "Evaluating Candidate Model:\n",
      "Parameters: {'color_hidden_size': 50, 'lr': 0.004, 'num_epochs': 1}\tScore: -0.11769071730060483\n",
      "{'num_epochs': 1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.001, 'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>} {'embed_dim': 100, 'hidden_dim': 100, 'vocab_size': 974, 'color_dim': 54}\n",
      "---EPOCH 0---\n",
      "=========================\n",
      "AFTER EPOCH 99 - AVERAGE VALIDATION LOSS: 1.6139799348637462\n",
      "=========================\n",
      "Evaluating Candidate Model:\n",
      "Parameters: {'color_hidden_size': 100, 'lr': 0.001, 'num_epochs': 1}\tScore: -0.03434776707752851\n",
      "{'num_epochs': 1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'lr': 0.004, 'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>} {'embed_dim': 100, 'hidden_dim': 100, 'vocab_size': 974, 'color_dim': 54}\n",
      "---EPOCH 0---\n",
      "=========================\n",
      "AFTER EPOCH 99 - AVERAGE VALIDATION LOSS: 2.2007299718633293\n",
      "=========================\n",
      "Evaluating Candidate Model:\n",
      "Parameters: {'color_hidden_size': 100, 'lr': 0.004, 'num_epochs': 1}\tScore: 0.15623398834939042\n"
     ]
    }
   ],
   "source": [
    "x = hyperparameter_search(pg, LiteralListener, CaptionEncoder, [train_X, train_y, assess_X, assess_y], literal_listener_assess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<models.LiteralListener at 0x14ef410b8>,\n",
       " {'color_hidden_size': 100, 'lr': 0.004, 'num_epochs': 1},\n",
       " [({'color_hidden_size': 50, 'lr': 0.001, 'num_epochs': 1},\n",
       "   -0.23228980693006493),\n",
       "  ({'color_hidden_size': 50, 'lr': 0.004, 'num_epochs': 1},\n",
       "   -0.11769071730060483),\n",
       "  ({'color_hidden_size': 100, 'lr': 0.001, 'num_epochs': 1},\n",
       "   -0.03434776707752851),\n",
       "  ({'color_hidden_size': 100, 'lr': 0.004, 'num_epochs': 1},\n",
       "   0.15623398834939042)])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([0.006511065487832984, 0.023409264572201046, 0.6525344613148397, 0.09153942832213081, 0.0019055160863379183, 0.002195713462865435, 0.1448486371158992, 0.007449071892645734, 0.06845598253083168, 0.49858460771894203, 0.05267798043761057, 0.29324368461662176, 0.9144715929980316, 0.1134261497010641, 0.17154708680082278, 0.005607378544412828, 7.812167852447264e-05, 0.06333848954337418, 0.9633538953296845, 0.011605059793079166, 0.8556798382579612, 0.18931032564737954, 0.1166264816611529, 0.5714283994675888, 0.25649961174125974, 0.41297865930497724, 0.7978049673014234, 0.3047420364644446, 0.8063982627374914, 0.32835220802086823, 0.2001534036175303, 0.05276737872809043, 0.08269850860288774, 0.002314080755694551, 0.4503065225107272, 0.1975493121434279, 0.25547086385817375, 0.9186077341337798, 0.6768080964413862, 0.0030063694388321686, 0.39580027519055905, 0.0023964067133358776, 0.1809097752651766, 0.044980412231280575, 0.11199719377032401, 0.5037079764207698, 0.0015147020215676664, 0.1665735468755542, 0.5762354043482538, 0.14418571292829307, 0.006411319066708746, 0.041272174078962186, 0.004344640528712232, 0.0201392888501235, 0.9953587805852087, 0.8299879082023517, 0.2468926126260226, 0.6466677614174884, 0.8242486119440646, 0.34690894766460656, 0.09823838280766233, 0.021839486407299106, 0.4769084038955761, 0.025082927191961132, 0.8002800267680534, 0.6547736151857817, 0.001833037777494593, 0.4148568419816999, 0.503092514085159, 0.33141704348114026, 0.4054090449127508, 0.005552567771134523, 0.5581252695012987, 0.20252008772154886, 0.007947802147097458, 0.954537964338813, 0.027183101706815125, 0.13083463179136667, 0.0009264151665071757, 0.03186110885427075, 0.23897450850269675, 0.972998867979999, 0.07901870529066095, 0.15202201475749666, 0.5528595062303509, 0.4674201920099895, 0.6071302121346576, 0.3124493471738203, 0.07134538991298571, 0.26224347756421307, 0.1495575507875468, 0.06697103773667995, 0.07494151370056636, 0.7321363155275477, 0.5891875218710468, 0.01618206455778802, 0.018867579293167583, 0.1903581828114284, 0.87716879901514, 0.7642459746172323])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

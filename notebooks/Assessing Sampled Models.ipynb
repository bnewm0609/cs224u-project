{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can use packages from parent directory\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from example experiments.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from monroe_data import MonroeData, MonroeDataEntry, Color # last two for reading pkl file\n",
    "import caption_featurizers\n",
    "from color_featurizers import ColorFeaturizer, color_phi_fourier\n",
    "from models import LiteralListener, LiteralSpeaker, ImaginativeListener, CaptionEncoder, CaptionGenerator, ColorGenerator, ColorSelector, ColorOnlyBaseline\n",
    "from evaluation import score_model, delta_e_dist, Speaker, Score\n",
    "from experiment import FeatureHandler, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import experiment\n",
    "importlib.reload(experiment)\n",
    "from experiment import FeatureHandler, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"../\"\n",
    "train_data = MonroeData(prefix + \"data/csv/train_corpus_monroe.csv\", prefix + \"data/entries/train_entries_monroe.pkl\")\n",
    "dev_data_synth  = MonroeData(prefix + \"data/csv/dev_corpus_synth_10fold.csv\", prefix + \"data/entries/dev_corpus_synth_10fold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_synth  = MonroeData(prefix + \"data/csv/test_corpus_synth_10fold.csv\", prefix + \"data/entries/test_corpus_synth_10fold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_score(eval_df, speaker=\"gameid\"):\n",
    "    \"\"\"\n",
    "    This is the scoring function that Julia came up with\n",
    "    \"\"\"\n",
    "    mean_scores = eval_df.groupby(speaker).numOutcome.mean()\n",
    "    mean_numCleanWords = eval_df.groupby(speaker).numCleanWords.mean()\n",
    "    mean_clkTime = eval_df.groupby(speaker).clkTime.mean()\n",
    "    true_scores = mean_scores / mean_clkTime / mean_numCleanWords\n",
    "    max_score = true_scores.max()\n",
    "    true_scores /= max_score # normalize the scores\n",
    "    return true_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Imaginative Listener\n",
    "def imaginative_listener(model_file=\"../model/imaginative_listener_with_distractors_linear100hd5epoch_GLOVE_MSE.params\"):\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer)\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "\n",
    "    def target_color_target(data_entry):\n",
    "        return np.array(data_entry.colors[0].rgb_norm)\n",
    "\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi, target_fn=target_color_target,\n",
    "                                randomized_colors=False) #using TEST data now :) \n",
    "\n",
    "    print(\"Obtaining training features\") # get features even if you're runnning the pretrained model for example\n",
    "    #train_features = feature_handler.train_features()\n",
    "    #train_targets = feature_handler.train_targets()\n",
    "\n",
    "    imaginative_model = ImaginativeListener(ColorGenerator, criterion=torch.nn.CosineEmbeddingLoss,\n",
    "                            optimizer=torch.optim.Adam, lr=0.004, num_epochs=5)\n",
    "\n",
    "    # Creating model\n",
    "    MSELossSum = lambda: nn.MSELoss(reduction='sum') # sorry for this ugliness..... but this is me passing a parameter to the loss func\n",
    "    imaginative_model = ImaginativeListener(ColorGenerator, criterion=MSELossSum,\n",
    "                                optimizer=torch.optim.Adam, lr=0.001, num_epochs=5, use_color=True)\n",
    "    imaginative_model.init_model(embed_dim=100, hidden_dim=50, vocab_size=feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                    color_in_dim=54, color_hidden_dim=50, weight_matrix=caption_featurizers.get_pretrained_glove(feature_handler.caption_featurizer.caption_indexer.idx2word.items(), 100, prefix=True))\n",
    "\n",
    "    imaginative_model.load_model(model_file)\n",
    "        \n",
    "    print(\"Evaluating model\")\n",
    "    output_to_score_de = lambda outputs, targets: np.array([delta_e_dist(outputs[i], targets[i]) for i in range(len(targets))])\n",
    "    # we want to score based on the model's predictions at the TARGET indices not listener clicked indices,\n",
    "    # so we change the feature_handler's target function to do that:\n",
    "    my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "    result = evaluate_model(test_data_synth, feature_handler, imaginative_model, output_to_score_de, my_score_model, accuracy=False)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imaginative_listener_samples():\n",
    "    model_directory = \"../imaginative_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating sample #{}\".format(i))\n",
    "        _, imaginative_listener_eval = imaginative_listener(model_file=\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        il_true_scores = imaginative_listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        il_model_scores = imaginative_listener_eval.groupby('gameid').model_scores.mean()\n",
    "        il_true_scores_composite = composite_score(imaginative_listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(il_model_scores, il_true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        #aggregate_accuracies.append(sum(imaginative_listener_eval.model_scores > 0.5)/len(imaginative_listener_eval.model_scores))\n",
    "        aggregate_accuracies.append(np.mean(imaginative_listener_eval.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        imaginative_listener_close = imaginative_listener_eval[imaginative_listener_eval.condition == \"close\"]\n",
    "        imaginative_listener_split = imaginative_listener_eval[imaginative_listener_eval.condition == \"split\"]\n",
    "        imaginative_listener_far = imaginative_listener_eval[imaginative_listener_eval.condition == \"far\"]\n",
    "\n",
    "        imaginative_listener_close_true_scores = imaginative_listener_close.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_close_model_scores = imaginative_listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        imaginative_listener_split_true_scores =  imaginative_listener_split.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_split_model_scores = imaginative_listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        imaginative_listener_far_true_scores =  imaginative_listener_far.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_far_model_scores = imaginative_listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        imaginative_listener_close_composite = composite_score(imaginative_listener_close)\n",
    "        imaginative_listener_split_composite = composite_score(imaginative_listener_split)\n",
    "        imaginative_listener_far_composite   = composite_score(imaginative_listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(imaginative_listener_close_composite, imaginative_listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(imaginative_listener_split_composite, imaginative_listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(imaginative_listener_far_composite, imaginative_listener_far_model_scores))\n",
    "\n",
    "    #     close_accuracies.append(sum(imaginative_listener_close_model_scores > 0.5)/len(imaginative_listener_close_model_scores))\n",
    "    #     split_accuracies.append(sum(imaginative_listener_split_model_scores > 0.5)/len(imaginative_listener_split_model_scores))\n",
    "    #     far_accuracies.append(sum(imaginative_listener_far_model_scores > 0.5)/len(imaginative_listener_far_model_scores))\n",
    "        close_accuracies.append(np.mean(imaginative_listener_close_model_scores))\n",
    "        split_accuracies.append(np.mean(imaginative_listener_split_model_scores))\n",
    "        far_accuracies.append(np.mean(imaginative_listener_far_model_scores))\n",
    "        \n",
    "        print(\"Most recent stats:\")\n",
    "        print(\"agg acc:\", aggregate_accuracies[-1])\n",
    "        print(\"clo acc:\", close_accuracies[-1])\n",
    "        print(\"spl acc:\", split_accuracies[-1])\n",
    "        print(\"far acc:\", far_accuracies[-1])\n",
    "        print(\"agg cor:\", aggregate_correlations[-1])\n",
    "        print(\"clo cor:\", close_correlations[-1])\n",
    "        print(\"spl cor:\", split_correlations[-1])\n",
    "        print(\"far cor:\", far_correlations[-1])\n",
    "        \n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sample #0\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.98516954890258\n",
      "clo acc: 18.27353323876809\n",
      "spl acc: 19.544536012224782\n",
      "far acc: 34.14159079769889\n",
      "agg cor: (-0.886422302978764, 4.250960310734327e-178)\n",
      "clo cor: (-0.455535609378521, 2.0635307187084423e-28)\n",
      "spl cor: (-0.5473674197436782, 1.3343968892457512e-42)\n",
      "far cor: (-0.8657290229509013, 3.1337385241772896e-160)\n",
      "Evaluating sample #1\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.211091965944536\n",
      "clo acc: 18.65899781108387\n",
      "spl acc: 19.767035392086786\n",
      "far acc: 34.21259842311515\n",
      "agg cor: (-0.8860109120142069, 1.0393073393501362e-177)\n",
      "clo cor: (-0.44432579193215566, 5.887339051429764e-27)\n",
      "spl cor: (-0.5267565591108372, 4.9684543265154734e-39)\n",
      "far cor: (-0.8675670970509768, 1.079527020742103e-161)\n",
      "Evaluating sample #2\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.95348429830869\n",
      "clo acc: 18.437027023551213\n",
      "spl acc: 19.35961898023499\n",
      "far acc: 34.067678865462305\n",
      "agg cor: (-0.8919397009031778, 1.8685858962595625e-183)\n",
      "clo cor: (-0.4667281491674002, 6.407980536865597e-30)\n",
      "spl cor: (-0.5717604401511618, 3.6777693898206863e-47)\n",
      "far cor: (-0.8686362282684238, 1.4867365072500277e-162)\n",
      "Evaluating sample #3\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.018430904966912\n",
      "clo acc: 18.49341611855365\n",
      "spl acc: 19.4753261426775\n",
      "far acc: 34.09191124694347\n",
      "agg cor: (-0.8866139971776391, 2.7993650643129003e-178)\n",
      "clo cor: (-0.43810811058861493, 3.581899902245579e-26)\n",
      "spl cor: (-0.5296433756282287, 1.624662845037862e-39)\n",
      "far cor: (-0.8647559216076199, 1.8270776453110162e-159)\n",
      "Evaluating sample #4\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.17482971481473\n",
      "clo acc: 18.62743453645803\n",
      "spl acc: 19.752563626397155\n",
      "far acc: 34.14945435477963\n",
      "agg cor: (-0.8894263476542338, 5.585736691209525e-181)\n",
      "clo cor: (-0.45758906376919695, 1.1018524984903104e-28)\n",
      "spl cor: (-0.5325362340054747, 5.242969797755635e-40)\n",
      "far cor: (-0.869522995700688, 2.8335708940723594e-163)\n",
      "Evaluating sample #5\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.143522513533853\n",
      "clo acc: 18.643209041814377\n",
      "spl acc: 19.732187550885364\n",
      "far acc: 34.06440540427714\n",
      "agg cor: (-0.8811402706142353, 3.1832120315640084e-173)\n",
      "clo cor: (-0.4513571761678967, 7.3012410470162385e-28)\n",
      "spl cor: (-0.5007576193660417, 7.324464823278248e-35)\n",
      "far cor: (-0.8612623408930862, 9.16923335417871e-157)\n",
      "Evaluating sample #6\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.06136433254021\n",
      "clo acc: 18.56301687867534\n",
      "spl acc: 19.482940637388445\n",
      "far acc: 34.14122255837141\n",
      "agg cor: (-0.8828030354822461, 9.859024596492022e-175)\n",
      "clo cor: (-0.4389762719390835, 2.7898971710967474e-26)\n",
      "spl cor: (-0.529100039751234, 2.0067346509033875e-39)\n",
      "far cor: (-0.8659216681301237, 2.2068141227299776e-160)\n",
      "Evaluating sample #7\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.9379978094873\n",
      "clo acc: 18.382157579668977\n",
      "spl acc: 19.335616835781217\n",
      "far acc: 34.09880858608765\n",
      "agg cor: (-0.8858832216885367, 1.3707229566334728e-177)\n",
      "clo cor: (-0.4398237282512436, 2.1844838924650963e-26)\n",
      "spl cor: (-0.5283483825166942, 2.686037528842471e-39)\n",
      "far cor: (-0.8721234305787758, 2.0436151820523473e-165)\n",
      "Evaluating sample #8\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.076479484977696\n",
      "clo acc: 18.52792076547755\n",
      "spl acc: 19.65772880690549\n",
      "far acc: 34.0518591217395\n",
      "agg cor: (-0.8861779195808417, 7.232834278650833e-178)\n",
      "clo cor: (-0.4560009902923457, 1.7906809857010429e-28)\n",
      "spl cor: (-0.5125048638174236, 1.0609677577036421e-36)\n",
      "far cor: (-0.864174951180753, 5.200680015809707e-159)\n",
      "Evaluating sample #9\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.046209328341682\n",
      "clo acc: 18.429641808519204\n",
      "spl acc: 19.693467715322047\n",
      "far acc: 34.02026095170745\n",
      "agg cor: (-0.881236884541505, 2.6049799234726472e-173)\n",
      "clo cor: (-0.42574145054982565, 1.1653168048128728e-24)\n",
      "spl cor: (-0.5195249596346924, 7.798792194683714e-38)\n",
      "far cor: (-0.8642056203554739, 4.921872349097669e-159)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_imaginative_listener_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../results/imaginative_listener_assessment.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8857654592635387"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['aggregate_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.225927799225445]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.50006086024096]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.470457996575014]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.710338275301137]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8799177945947197, 1.4376357425904765e-168)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.4409533567945598, 5.226923223263904e-26)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8577761621065179, 5.865956224847408e-151)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.5079681530415953, 2.896292325793216e-35)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Literal Listener\n",
    "# -----------------------------------------\n",
    "# TODO: FILL IN PARAMETERS \n",
    "def literal_listener_experiment(train=False, epochs=5, embed_dim = 100, hidden_dim = 100, color_dim= 54, model_file=\"../model/literal_listener_5epoch-2.params\"):\n",
    "\n",
    "    # Initializing featurizers\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer) # Use with parameter files that end in `endings_tkn`\n",
    "    # caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.WhitespaceTokenizer) # Use with parameter files don't\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi) # target function is initialized by default\n",
    "\n",
    "    print(\"Initializing model\")\n",
    "    model = LiteralListener(CaptionEncoder, num_epochs = epochs)\n",
    "    model.init_model(embed_dim = embed_dim, hidden_dim = hidden_dim, vocab_size = feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                 color_dim = color_dim)\n",
    "\n",
    "    print(model_file)\n",
    "    model.load_model(model_file)\n",
    "\n",
    "    # convert the model output to a score for that particular round\n",
    "    print(\"Evaluating model\")\n",
    "    output_to_score = lambda model_outputs, targets: np.exp(model_outputs[np.arange(len(model_outputs)), targets]) # get the model's predicted probablity at each target index and use that as the score\n",
    "    my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "    eval_p = evaluate_model(test_data_synth, feature_handler, model, output_to_score, my_score_model, accuracy=False)\n",
    "\n",
    "    output_to_score_acc = lambda model_outputs, targets: np.argmax(model_outputs, axis=1) == targets\n",
    "    eval_acc = evaluate_model(test_data_synth, feature_handler, model, output_to_score_acc, my_score_model, accuracy=False)\n",
    "    \n",
    "    return (eval_p, eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume pragmatic will either be similar or need its own type of thing\n",
    "def evaluate_literal_listener_samples():\n",
    "    model_directory = \"../literal_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating Literal Listener #{}\".format(i))\n",
    "        listener_eval, listener_eval_acc = literal_listener_experiment(model_file=\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        _, listener_eval = listener_eval         # first item is correlation, which we will recalculate\n",
    "        _, listener_eval_acc = listener_eval_acc # first item is correlation, which we will recalculate\n",
    "        \n",
    "        true_scores = listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        model_scores = listener_eval.groupby('gameid').model_scores.mean()\n",
    "        true_scores_composite = composite_score(listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(model_scores, true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        aggregate_accuracies.append(sum(listener_eval_acc.model_scores)/len(listener_eval_acc.model_scores))\n",
    "\n",
    "\n",
    "        # separate out conditions\n",
    "        listener_close = listener_eval[listener_eval.condition == \"close\"]\n",
    "        listener_split = listener_eval[listener_eval.condition == \"split\"]\n",
    "        listener_far =   listener_eval[listener_eval.condition == \"far\"]\n",
    "        \n",
    "        listener_close_acc = listener_eval_acc[listener_eval_acc.condition == \"close\"]\n",
    "        listener_split_acc = listener_eval_acc[listener_eval_acc.condition == \"split\"]\n",
    "        listener_far_acc =   listener_eval_acc[listener_eval_acc.condition == \"far\"]\n",
    "\n",
    "        listener_close_true_scores =  listener_close.groupby('gameid').numOutcome.mean()\n",
    "        listener_close_model_scores = listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_split_true_scores =  listener_split.groupby('gameid').numOutcome.mean()\n",
    "        listener_split_model_scores = listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_far_true_scores =  listener_far.groupby('gameid').numOutcome.mean()\n",
    "        listener_far_model_scores = listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        listener_close_composite = composite_score(listener_close)\n",
    "        listener_split_composite = composite_score(listener_split)\n",
    "        listener_far_composite   = composite_score(listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(listener_close_composite, listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(listener_split_composite, listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(listener_far_composite,     listener_far_model_scores))\n",
    "\n",
    "        close_accuracies.append(sum(listener_close_acc.model_scores)/len(listener_close_acc.model_scores))\n",
    "        split_accuracies.append(sum(listener_split_acc.model_scores)/len(listener_split_acc.model_scores))\n",
    "        far_accuracies.append(sum(  listener_far_acc.model_scores)/len(listener_far_acc.model_scores))\n",
    "\n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Literal Listener #0\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_0.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #1\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_1.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #2\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_2.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #3\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_3.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #4\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_4.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #5\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_5.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #6\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_6.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #7\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_7.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #8\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_8.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #9\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_9.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n"
     ]
    }
   ],
   "source": [
    "lit_list_results = evaluate_literal_listener_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.4652272727272727,\n",
       "  0.465,\n",
       "  0.465530303030303,\n",
       "  0.46541666666666665,\n",
       "  0.46541666666666665,\n",
       "  0.4625,\n",
       "  0.46579545454545457,\n",
       "  0.46795454545454546,\n",
       "  0.46299242424242426,\n",
       "  0.4668181818181818],\n",
       " 'aggregate_correlations': [(0.9551759145546841, 3.0935846835781653e-280),\n",
       "  (0.9568476243580771, 1.7621962353396275e-284),\n",
       "  (0.9603190679507451, 7.374375789094369e-294),\n",
       "  (0.9574546896746611, 4.602201869499246e-286),\n",
       "  (0.9577112363404624, 9.704977797334284e-287),\n",
       "  (0.95267599364886, 3.502568069624804e-274),\n",
       "  (0.9572465184635212, 1.6159093251291917e-285),\n",
       "  (0.9620378666348999, 8.114004343696587e-299),\n",
       "  (0.9534726902789679, 4.480954099693109e-276),\n",
       "  (0.9591990329967709, 9.599559029309213e-291)],\n",
       " 'close_accuracies': [0.4375,\n",
       "  0.43886363636363634,\n",
       "  0.44363636363636366,\n",
       "  0.44022727272727274,\n",
       "  0.43977272727272726,\n",
       "  0.43136363636363634,\n",
       "  0.4420454545454545,\n",
       "  0.4456818181818182,\n",
       "  0.4335227272727273,\n",
       "  0.44136363636363635],\n",
       " 'close_correlations': [(0.8555252142199525, 1.741017060244865e-152),\n",
       "  (0.8691192090736207, 6.036583379785247e-163),\n",
       "  (0.8772251873263902, 9.298874142127538e-170),\n",
       "  (0.8634652296862623, 1.8543613724213807e-158),\n",
       "  (0.8689150024862048, 8.840669038050947e-163),\n",
       "  (0.8494152224904484, 3.965338041778415e-148),\n",
       "  (0.8625988087008658, 8.670255081864967e-158),\n",
       "  (0.8752687926788666, 4.529123327233953e-168),\n",
       "  (0.847996289749164, 3.8244212159383906e-147),\n",
       "  (0.8771625910320515, 1.0540762229753714e-169)],\n",
       " 'far_accuracies': [0.48113636363636364,\n",
       "  0.4813636363636364,\n",
       "  0.4813636363636364,\n",
       "  0.48068181818181815,\n",
       "  0.4807954545454545,\n",
       "  0.4813636363636364,\n",
       "  0.4818181818181818,\n",
       "  0.4822727272727273,\n",
       "  0.48102272727272727,\n",
       "  0.48204545454545455],\n",
       " 'far_correlations': [(0.947614351951208, 7.188466065594215e-263),\n",
       "  (0.9470192712163961, 1.2947271190747092e-261),\n",
       "  (0.9488472839758789, 1.614301250303917e-265),\n",
       "  (0.9482862266784527, 2.638292872444917e-264),\n",
       "  (0.9436172423878592, 1.0530511597130046e-254),\n",
       "  (0.9432168243417004, 6.417919746337178e-254),\n",
       "  (0.9474363681049539, 1.7127329837754712e-262),\n",
       "  (0.9481268619884562, 5.800930420283577e-264),\n",
       "  (0.9459012051667844, 2.7064595136462336e-259),\n",
       "  (0.9469762642891872, 1.59350910327607e-261)],\n",
       " 'split_accuracies': [0.47704545454545455,\n",
       "  0.4747727272727273,\n",
       "  0.4715909090909091,\n",
       "  0.4753409090909091,\n",
       "  0.4756818181818182,\n",
       "  0.4747727272727273,\n",
       "  0.47352272727272726,\n",
       "  0.4759090909090909,\n",
       "  0.4744318181818182,\n",
       "  0.47704545454545455],\n",
       " 'split_correlations': [(0.8893009352720618, 7.396627755845392e-181),\n",
       "  (0.8832580304489884, 3.774953981147329e-175),\n",
       "  (0.898926455703963, 1.134030807773572e-190),\n",
       "  (0.8946369925092016, 3.513306632979373e-186),\n",
       "  (0.8884317671193951, 5.1310289242041145e-180),\n",
       "  (0.8676280619281048, 9.645820355416179e-162),\n",
       "  (0.894595705748284, 3.872535341265909e-186),\n",
       "  (0.9047277723818176, 4.4538874612821826e-197),\n",
       "  (0.8831824786820708, 4.428551429210225e-175),\n",
       "  (0.8941360489796825, 1.141612295423892e-185)]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/literal_listener_assessment_true_acc.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lit_list_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.46049242424242426,\n",
       "  0.4615530303030303,\n",
       "  0.45943181818181816,\n",
       "  0.46018939393939395,\n",
       "  0.4612878787878788,\n",
       "  0.45943181818181816,\n",
       "  0.4622727272727273,\n",
       "  0.4640530303030303,\n",
       "  0.45928030303030304,\n",
       "  0.46291666666666664],\n",
       " 'aggregate_correlations': [(0.9551759148646606, 3.0935791851169376e-280),\n",
       "  (0.9568476244064827, 1.7621957268376714e-284),\n",
       "  (0.9603190673145864, 7.374406257773924e-294),\n",
       "  (0.9574546888418075, 4.602225052553829e-286),\n",
       "  (0.9577112364008573, 9.704974230231723e-287),\n",
       "  (0.9526759938115862, 3.502564978285354e-274),\n",
       "  (0.9572465172587161, 1.6159210417650658e-285),\n",
       "  (0.9620378670937882, 8.113979043277967e-299),\n",
       "  (0.9534726907653601, 4.4809420710264456e-276),\n",
       "  (0.9591990326239181, 9.599581623980341e-291)],\n",
       " 'close_accuracies': [0.38825757575757575,\n",
       "  0.4147727272727273,\n",
       "  0.38446969696969696,\n",
       "  0.3996212121212121,\n",
       "  0.39015151515151514,\n",
       "  0.3693181818181818,\n",
       "  0.3996212121212121,\n",
       "  0.42045454545454547,\n",
       "  0.38446969696969696,\n",
       "  0.4034090909090909],\n",
       " 'close_correlations': [(0.855525213572353, 1.7410189542019432e-152),\n",
       "  (0.8691192042449603, 6.036637884990569e-163),\n",
       "  (0.8772251833362054, 9.298948468391645e-170),\n",
       "  (0.8634652336927975, 1.8543481012862976e-158),\n",
       "  (0.8689150021400572, 8.840674750647576e-163),\n",
       "  (0.8494152250813579, 3.965321547293733e-148),\n",
       "  (0.8625988103758551, 8.670229318031713e-158),\n",
       "  (0.8752687942627781, 4.529109199135237e-168),\n",
       "  (0.8479962924697155, 3.824404682359527e-147),\n",
       "  (0.8771625906591279, 1.054077009969399e-169)],\n",
       " 'far_accuracies': [0.4696969696969697,\n",
       "  0.4810606060606061,\n",
       "  0.4696969696969697,\n",
       "  0.4753787878787879,\n",
       "  0.48484848484848486,\n",
       "  0.4753787878787879,\n",
       "  0.4734848484848485,\n",
       "  0.4734848484848485,\n",
       "  0.4791666666666667,\n",
       "  0.4715909090909091],\n",
       " 'far_correlations': [(0.9476143513266879, 7.18848800267197e-263),\n",
       "  (0.9470192703211613, 1.2947327175152507e-261),\n",
       "  (0.9488472839030531, 1.614301839007367e-265),\n",
       "  (0.9482862272574941, 2.638285307769947e-264),\n",
       "  (0.9436172426980212, 1.0530496800477131e-254),\n",
       "  (0.9432168247909891, 6.417906778197712e-254),\n",
       "  (0.9474363668726197, 1.7127432615804325e-262),\n",
       "  (0.9481268629690013, 5.800902343390754e-264),\n",
       "  (0.9459012047962954, 2.706464253851785e-259),\n",
       "  (0.9469762642213896, 1.5935096246600806e-261)],\n",
       " 'split_accuracies': [0.4734848484848485,\n",
       "  0.4696969696969697,\n",
       "  0.4734848484848485,\n",
       "  0.48484848484848486,\n",
       "  0.48484848484848486,\n",
       "  0.4734848484848485,\n",
       "  0.4734848484848485,\n",
       "  0.4772727272727273,\n",
       "  0.4696969696969697,\n",
       "  0.4810606060606061],\n",
       " 'split_correlations': [(0.8893009351888765, 7.396629132695641e-181),\n",
       "  (0.8832580301709915, 3.774956199956075e-175),\n",
       "  (0.8989264543215286, 1.1340346717061795e-190),\n",
       "  (0.894636990539324, 3.5133229552145458e-186),\n",
       "  (0.8884317676328783, 5.13102307741107e-180),\n",
       "  (0.867628065830485, 9.6457508257869e-162),\n",
       "  (0.894595702900694, 3.8725613378922735e-186),\n",
       "  (0.9047277722382036, 4.4538891394010366e-197),\n",
       "  (0.8831824777767148, 4.4285599004887074e-175),\n",
       "  (0.8941360470588509, 1.141617441130678e-185)]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Baseline Listener\n",
    "# -----------------------------------------\n",
    "def baseline_listener_experiment(train=False, model_file=\"../model/baseline_model.params\"):\n",
    "\n",
    "    # Initializing featurizers\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer) # Use with parameter files that end in `endings_tkn`\n",
    "    # caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.WhitespaceTokenizer) # Use with parameter files don't\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi) # target function is initialized by default\n",
    "\n",
    "    print(\"Initializing model\")\n",
    "    model = ColorOnlyBaseline(ColorSelector, optimizer=torch.optim.Adam, lr=0.001, num_epochs=5)\n",
    "    model.init_model(color_dim=54)\n",
    "\n",
    "    print(model_file)\n",
    "    model.load_model(model_file)\n",
    "\n",
    "    # convert the model output to a score for that particular round\n",
    "    print(\"Evaluating model\")\n",
    "    output_to_score = lambda model_outputs, targets: np.exp(model_outputs[np.arange(len(model_outputs)), targets]) # get the model's predicted probablity at each target index and use that as the score\n",
    "    my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "    eval_p = evaluate_model(test_data_synth, feature_handler, model, output_to_score, my_score_model, accuracy=False)\n",
    "\n",
    "\n",
    "    output_to_score_acc = lambda model_outputs, targets: np.argmax(model_outputs, axis=1) == targets\n",
    "    eval_acc = evaluate_model(test_data_synth, feature_handler, model, output_to_score_acc, my_score_model, accuracy=False)\n",
    "    \n",
    "    return (eval_p, eval_acc)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just noting that there are two sources of randomness: one is in the order the colors are presented and the other is the model's training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume pragmatic will either be similar or need its own type of thing\n",
    "def evaluate_baseline_listener_samples():\n",
    "    model_directory = \"../baseline_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating Baseline Listener #{}\".format(i))\n",
    "        listener_eval, listener_eval_acc = baseline_listener_experiment(model_file=\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        _, listener_eval = listener_eval # first item is correlation, which we will recalculate\n",
    "        _, listener_eval_acc = listener_eval_acc # first item is correlation, which we will recalculate\n",
    "        true_scores = listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        model_scores = listener_eval.groupby('gameid').model_scores.mean()\n",
    "        true_scores_composite = composite_score(listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(model_scores, true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        aggregate_accuracies.append(sum(listener_eval_acc.model_scores)/len(listener_eval_acc.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        listener_close = listener_eval[listener_eval.condition == \"close\"]\n",
    "        listener_split = listener_eval[listener_eval.condition == \"split\"]\n",
    "        listener_far   = listener_eval[listener_eval.condition == \"far\"]\n",
    "        \n",
    "        listener_close_acc = listener_eval_acc[listener_eval_acc.condition == \"close\"]\n",
    "        listener_split_acc = listener_eval_acc[listener_eval_acc.condition == \"split\"]\n",
    "        listener_far_acc   = listener_eval_acc[listener_eval_acc.condition == \"far\"]\n",
    "\n",
    "        listener_close_true_scores =  listener_close.groupby('gameid').numOutcome.mean()\n",
    "        listener_close_model_scores = listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_split_true_scores =  listener_split.groupby('gameid').numOutcome.mean()\n",
    "        listener_split_model_scores = listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_far_true_scores =  listener_far.groupby('gameid').numOutcome.mean()\n",
    "        listener_far_model_scores = listener_far.groupby('gameid').model_scores.mean()\n",
    "        \n",
    "        # turn true scores to composite, gricean scores\n",
    "        listener_close_composite = composite_score(listener_close)\n",
    "        listener_split_composite = composite_score(listener_split)\n",
    "        listener_far_composite   = composite_score(listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(listener_close_composite, listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(listener_split_composite, listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(  listener_far_composite  , listener_far_model_scores))\n",
    "\n",
    "        close_accuracies.append(sum(listener_close_acc.model_scores)/ len(listener_close_acc.model_scores))\n",
    "        split_accuracies.append(sum(listener_split_acc.model_scores)/ len(listener_split_acc.model_scores))\n",
    "        far_accuracies.append(  sum(listener_far_acc.model_scores)  / len(listener_far_acc.model_scores))\n",
    "\n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Listener #0\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_0.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #1\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_1.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #2\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_2.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #3\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_3.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #4\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_4.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #5\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_5.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #6\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_6.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #7\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_7.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #8\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_8.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n",
      "Evaluating Baseline Listener #9\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../baseline_listener_samples/sample_9.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n"
     ]
    }
   ],
   "source": [
    "baseline_list_results = evaluate_baseline_listener_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.37575757575757573,\n",
       "  0.33367424242424243,\n",
       "  0.3375378787878788,\n",
       "  0.3346969696969697,\n",
       "  0.3334469696969697,\n",
       "  0.33837121212121213,\n",
       "  0.33829545454545457,\n",
       "  0.33265151515151514,\n",
       "  0.33382575757575755,\n",
       "  0.3346590909090909],\n",
       " 'aggregate_correlations': [(0.05179548924097473, 0.23477563700595694),\n",
       "  (-0.009098554629149352, 0.834777927560781),\n",
       "  (0.027786434212799433, 0.5240639701217923),\n",
       "  (0.007695292785320762, 0.8599734963671637),\n",
       "  (-0.042234798793224636, 0.332737824226761),\n",
       "  (-0.01870782040291889, 0.668002026978048),\n",
       "  (0.07613760691163626, 0.08048126238032255),\n",
       "  (0.05845904067603059, 0.17983925541334453),\n",
       "  (-0.012640497244356912, 0.7719847736291139),\n",
       "  (0.0009980441765262324, 0.9817468212819142)],\n",
       " 'close_accuracies': [0.3302272727272727,\n",
       "  0.3264772727272727,\n",
       "  0.3390909090909091,\n",
       "  0.33340909090909093,\n",
       "  0.33181818181818185,\n",
       "  0.34125,\n",
       "  0.34329545454545457,\n",
       "  0.3331818181818182,\n",
       "  0.33579545454545456,\n",
       "  0.34125],\n",
       " 'close_correlations': [(-0.018359313066958646, 0.6738277035476119),\n",
       "  (0.0009634123472714904, 0.982380096509008),\n",
       "  (-0.024172903884749564, 0.5794312981842771),\n",
       "  (0.055615793483561035, 0.2019864291169705),\n",
       "  (-0.036719880278642425, 0.3997639435404964),\n",
       "  (-0.04293387185115617, 0.3247905058213625),\n",
       "  (0.019675500438028886, 0.6519313534577525),\n",
       "  (-0.013589888521022308, 0.7553854533773585),\n",
       "  (0.05352512819189927, 0.21949230793281205),\n",
       "  (0.01142579022792988, 0.7933746480329424)],\n",
       " 'far_accuracies': [0.32886363636363636,\n",
       "  0.3392045454545455,\n",
       "  0.3396590909090909,\n",
       "  0.3281818181818182,\n",
       "  0.33636363636363636,\n",
       "  0.33590909090909093,\n",
       "  0.3367045454545455,\n",
       "  0.3343181818181818,\n",
       "  0.3285227272727273,\n",
       "  0.32954545454545453],\n",
       " 'far_correlations': [(0.06958578024972839, 0.11024199986553951),\n",
       "  (0.056464247507091836, 0.1951794171630859),\n",
       "  (0.014293106224607994, 0.743161996048034),\n",
       "  (-0.01406169701370469, 0.7471774415687263),\n",
       "  (0.07002792813283218, 0.10799311674908316),\n",
       "  (0.013767595280499065, 0.7522906141365994),\n",
       "  (-0.00685870171617743, 0.8750641368889074),\n",
       "  (0.08030297039382886, 0.0652083302259066),\n",
       "  (-0.03521152778767243, 0.41941755512296397),\n",
       "  (-0.06548726213524059, 0.13288291313406309)],\n",
       " 'split_accuracies': [0.4681818181818182,\n",
       "  0.3353409090909091,\n",
       "  0.33386363636363636,\n",
       "  0.3425,\n",
       "  0.3321590909090909,\n",
       "  0.33795454545454545,\n",
       "  0.33488636363636365,\n",
       "  0.33045454545454545,\n",
       "  0.3371590909090909,\n",
       "  0.3331818181818182],\n",
       " 'split_correlations': [(0.015915150875934675, 0.7152168720423995),\n",
       "  (-0.06712869404441768, 0.12341846732137988),\n",
       "  (0.05880918225067405, 0.1772414390634065),\n",
       "  (0.01421350028350075, 0.7445425500130252),\n",
       "  (-0.08255939916435287, 0.057984916569270295),\n",
       "  (-0.04975204477922182, 0.2537815671598003),\n",
       "  (0.1211561675774643, 0.005309443422191333),\n",
       "  (-0.002033180709819333, 0.9628254488289437),\n",
       "  (0.0019495789253920952, 0.964352982438961),\n",
       "  (0.027925935183877256, 0.5219819935457888)]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing featurizers\n",
      "Initializing model\n",
      "../model/baseline_model.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Got here to composite score\n"
     ]
    }
   ],
   "source": [
    "baseline_results_test = baseline_listener_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0670447301558705, 0.007602225488752366)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.05479847871132265, 0.029193110763098763)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    #a = 1.0 * np.array(data)\n",
    "    a = data\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    print(\"${:.4f}\\pm{:.4f}$\".format(m, h))\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9467041899156712, 0.9453345265907224, 0.94807385324062)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([l[0] for l in lit_list_results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001369663324948811"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9467041899156712-0.9453345265907224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9467041899156712-0.001369663324948811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9551759148646606, 3.0935791851169376e-280),\n",
       " (0.9568476244064827, 1.7621957268376714e-284),\n",
       " (0.9603190673145864, 7.374406257773924e-294),\n",
       " (0.9574546888418075, 4.602225052553829e-286),\n",
       " (0.9577112364008573, 9.704974230231723e-287),\n",
       " (0.9526759938115862, 3.502564978285354e-274),\n",
       " (0.9572465172587161, 1.6159210417650658e-285),\n",
       " (0.9620378670937882, 8.113979043277967e-299),\n",
       " (0.9534726907653601, 4.4809420710264456e-276),\n",
       " (0.9591990326239181, 9.599581623980341e-291)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_list_results['aggregate_correlations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46109090909090905, 0.4599297914836187, 0.4622520266981994)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(lit_list_results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001161117607290374"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4599297914836187-0.46109090909090905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4599297914836187-0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8663899276716822, -0.8686320928835145, -0.8641477624598499)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([l[0] for l in results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008684566179368414"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.8663899276716822--0.8686320928835145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7350220205551967"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.8663899276716822-0.008684566179368414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.060857990181823, 23.994688173655458, 24.12702780670819)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06616981652636511"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.060857990181823-23.994688173655458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.12702780670819"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.060857990181823+0.06616981652636511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "prag_list_results = None\n",
    "with open(\"../results/pragmatic_listener_assessment_accuracy.pkl\", \"rb\") as file:\n",
    "    prag_list_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.4533333333333333,\n",
       "  0.4526136363636364,\n",
       "  0.4530681818181818,\n",
       "  0.4536742424242424,\n",
       "  0.4531439393939394,\n",
       "  0.45325757575757575,\n",
       "  0.4536742424242424,\n",
       "  0.4530681818181818,\n",
       "  0.45268939393939395,\n",
       "  0.4520075757575758],\n",
       " 'aggregate_correlations': [(0.9615612280860988, 2.027065475884201e-297),\n",
       "  (0.9618056146561487, 3.91275795421677e-298),\n",
       "  (0.9617898446679253, 4.352331620136946e-298),\n",
       "  (0.9618575041863672, 2.7555019753713967e-298),\n",
       "  (0.9615458400800124, 2.2474727470917922e-297),\n",
       "  (0.9617135918003048, 7.278264227716953e-298),\n",
       "  (0.9619005374934682, 2.059438343024509e-298),\n",
       "  (0.9616903550580581, 8.511110396845046e-298),\n",
       "  (0.9616526527680964, 1.0968855063184333e-297),\n",
       "  (0.9616802273009595, 9.111561381510886e-298)],\n",
       " 'close_accuracies': [0.3958333333333333,\n",
       "  0.3958333333333333,\n",
       "  0.3977272727272727,\n",
       "  0.3996212121212121,\n",
       "  0.3958333333333333,\n",
       "  0.3939393939393939,\n",
       "  0.3996212121212121,\n",
       "  0.3939393939393939,\n",
       "  0.3958333333333333,\n",
       "  0.3958333333333333],\n",
       " 'close_correlations': [(0.8843297609118992, 3.872164319504565e-176),\n",
       "  (0.8848152723866364, 1.3699707986864544e-176),\n",
       "  (0.884273514628581, 4.366154929409032e-176),\n",
       "  (0.8852024247153802, 5.962476330012655e-177),\n",
       "  (0.8845804980946806, 2.2655190787870958e-176),\n",
       "  (0.885533359474058, 2.9212596123382614e-177),\n",
       "  (0.8845030125012531, 2.6740129980855973e-176),\n",
       "  (0.8836033953513593, 1.8167030861638095e-175),\n",
       "  (0.8847657641805122, 1.523414317665323e-176),\n",
       "  (0.8836154266152582, 1.7709275512704422e-175)],\n",
       " 'far_accuracies': [0.4791666666666667,\n",
       "  0.4772727272727273,\n",
       "  0.4810606060606061,\n",
       "  0.48484848484848486,\n",
       "  0.4810606060606061,\n",
       "  0.4810606060606061,\n",
       "  0.4772727272727273,\n",
       "  0.4791666666666667,\n",
       "  0.4791666666666667,\n",
       "  0.4791666666666667],\n",
       " 'far_correlations': [(0.9483566745606177, 1.860876599935368e-264),\n",
       "  (0.9486021133031725, 5.493672621543954e-265),\n",
       "  (0.9486098180776468, 5.286735623781734e-265),\n",
       "  (0.948290673795137, 2.5808275567760673e-264),\n",
       "  (0.9483719907982654, 1.724759552066711e-264),\n",
       "  (0.9488135565629366, 1.9112112962024947e-265),\n",
       "  (0.9487779299411102, 2.2840618096050038e-265),\n",
       "  (0.9485599516132441, 6.777451693303814e-265),\n",
       "  (0.9485193563703943, 8.294858989367822e-265),\n",
       "  (0.9486529539267797, 4.263660905284032e-265)],\n",
       " 'split_accuracies': [0.4583333333333333,\n",
       "  0.4602272727272727,\n",
       "  0.4564393939393939,\n",
       "  0.45454545454545453,\n",
       "  0.4583333333333333,\n",
       "  0.4564393939393939,\n",
       "  0.4602272727272727,\n",
       "  0.4602272727272727,\n",
       "  0.4583333333333333,\n",
       "  0.4583333333333333],\n",
       " 'split_correlations': [(0.9043391371918844, 1.231954585039109e-196),\n",
       "  (0.9045086724165378, 7.90817678217521e-197),\n",
       "  (0.9045104181465087, 7.872127210199812e-197),\n",
       "  (0.9050367711212649, 1.9772739881878502e-197),\n",
       "  (0.9042874883555962, 1.4098528863432917e-196),\n",
       "  (0.9044775695172081, 8.578724866430755e-197),\n",
       "  (0.90449790978604, 8.134085906847147e-197),\n",
       "  (0.9054372874656674, 6.872846520928148e-198),\n",
       "  (0.904899646253739, 2.836102987932115e-197),\n",
       "  (0.90451300512035, 7.819006541732408e-197)]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prag_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.4693\\pm0.0004$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46928787878787875, 0.4688625358768855, 0.46971322169887203)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(prag_list_results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.9486\\pm0.0001$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9485555018949304, 0.9484303757518484, 0.9486806280380125)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([l[0] for l in prag_list_results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.3373\\pm0.0102$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.33731439393939394, 0.32710468050521974, 0.34752410737356815)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(baseline_list_results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.4653\\pm0.0011$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46526515151515146, 0.46412343363903413, 0.4664068693912688)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(lit_list_results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

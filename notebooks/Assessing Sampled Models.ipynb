{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can use packages from parent directory\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from example experiments.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from monroe_data import MonroeData, MonroeDataEntry, Color # last two for reading pkl file\n",
    "import caption_featurizers\n",
    "from color_featurizers import ColorFeaturizer, color_phi_fourier\n",
    "from models import LiteralListener, LiteralSpeaker, ImaginativeListener, CaptionEncoder, CaptionGenerator, ColorGenerator\n",
    "from evaluation import score_model, delta_e_dist, Speaker, Score\n",
    "from experiment import FeatureHandler, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import experiment\n",
    "importlib.reload(experiment)\n",
    "from experiment import FeatureHandler, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"../\"\n",
    "train_data = MonroeData(prefix + \"data/csv/train_corpus_monroe.csv\", prefix + \"data/entries/train_entries_monroe.pkl\")\n",
    "dev_data_synth  = MonroeData(prefix + \"data/csv/dev_corpus_synth_10fold.csv\", prefix + \"data/entries/dev_corpus_synth_10fold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_synth  = MonroeData(prefix + \"data/csv/test_corpus_synth_10fold.csv\", prefix + \"data/entries/test_corpus_synth_10fold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_score(eval_df, speaker=\"gameid\"):\n",
    "    mean_scores = eval_df.groupby(speaker).numOutcome.mean()\n",
    "    mean_numCleanWords = eval_df.groupby(speaker).numCleanWords.mean()\n",
    "    mean_clkTime = eval_df.groupby(speaker).clkTime.mean()\n",
    "    true_scores = mean_scores / mean_clkTime / mean_numCleanWords\n",
    "    max_score = true_scores.max()\n",
    "    true_scores /= max_score # normalize the scores\n",
    "    return true_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Imaginative Listener\n",
    "def imaginative_listener(model_file=\"../model/imaginative_listener_with_distractors_linear100hd5epoch_GLOVE_MSE.params\"):\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer)\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "\n",
    "    def target_color_target(data_entry):\n",
    "        return np.array(data_entry.colors[0].rgb_norm)\n",
    "\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi, target_fn=target_color_target,\n",
    "                                randomized_colors=False) #using TEST data now :) \n",
    "\n",
    "    print(\"Obtaining training features\") # get features even if you're runnning the pretrained model for example\n",
    "    #train_features = feature_handler.train_features()\n",
    "    #train_targets = feature_handler.train_targets()\n",
    "\n",
    "    imaginative_model = ImaginativeListener(ColorGenerator, criterion=torch.nn.CosineEmbeddingLoss,\n",
    "                            optimizer=torch.optim.Adam, lr=0.004, num_epochs=5)\n",
    "\n",
    "    # Creating model\n",
    "    MSELossSum = lambda: nn.MSELoss(reduction='sum') # sorry for this ugliness..... but this is me passing a parameter to the loss func\n",
    "    imaginative_model = ImaginativeListener(ColorGenerator, criterion=MSELossSum,\n",
    "                                optimizer=torch.optim.Adam, lr=0.001, num_epochs=5, use_color=True)\n",
    "    imaginative_model.init_model(embed_dim=100, hidden_dim=50, vocab_size=feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                    color_in_dim=54, color_hidden_dim=50, weight_matrix=caption_featurizers.get_pretrained_glove(feature_handler.caption_featurizer.caption_indexer.idx2word.items(), 100, prefix=True))\n",
    "\n",
    "    imaginative_model.load_model(model_file)\n",
    "        \n",
    "    print(\"Evaluating model\")\n",
    "    output_to_score_de = lambda outputs, targets: np.array([delta_e_dist(outputs[i], targets[i]) for i in range(len(targets))])\n",
    "    # we want to score based on the model's predictions at the TARGET indices not listener clicked indices,\n",
    "    # so we change the feature_handler's target function to do that:\n",
    "    my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "    result = evaluate_model(test_data_synth, feature_handler, imaginative_model, output_to_score_de, my_score_model, accuracy=False)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imaginative_listener_samples():\n",
    "    model_directory = \"../imaginative_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating sample #{}\".format(i))\n",
    "        _, imaginative_listener_eval = imaginative_listener(model_file=\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        il_true_scores = imaginative_listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        il_model_scores = imaginative_listener_eval.groupby('gameid').model_scores.mean()\n",
    "        il_true_scores_composite = composite_score(imaginative_listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(il_model_scores, il_true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        #aggregate_accuracies.append(sum(imaginative_listener_eval.model_scores > 0.5)/len(imaginative_listener_eval.model_scores))\n",
    "        aggregate_accuracies.append(np.mean(imaginative_listener_eval.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        imaginative_listener_close = imaginative_listener_eval[imaginative_listener_eval.condition == \"close\"]\n",
    "        imaginative_listener_split = imaginative_listener_eval[imaginative_listener_eval.condition == \"split\"]\n",
    "        imaginative_listener_far = imaginative_listener_eval[imaginative_listener_eval.condition == \"far\"]\n",
    "\n",
    "        imaginative_listener_close_true_scores = imaginative_listener_close.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_close_model_scores = imaginative_listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        imaginative_listener_split_true_scores =  imaginative_listener_split.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_split_model_scores = imaginative_listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        imaginative_listener_far_true_scores =  imaginative_listener_far.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_far_model_scores = imaginative_listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        imaginative_listener_close_composite = composite_score(imaginative_listener_close)\n",
    "        imaginative_listener_split_composite = composite_score(imaginative_listener_split)\n",
    "        imaginative_listener_far_composite   = composite_score(imaginative_listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(imaginative_listener_close_composite, imaginative_listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(imaginative_listener_split_composite, imaginative_listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(imaginative_listener_far_composite, imaginative_listener_far_model_scores))\n",
    "\n",
    "    #     close_accuracies.append(sum(imaginative_listener_close_model_scores > 0.5)/len(imaginative_listener_close_model_scores))\n",
    "    #     split_accuracies.append(sum(imaginative_listener_split_model_scores > 0.5)/len(imaginative_listener_split_model_scores))\n",
    "    #     far_accuracies.append(sum(imaginative_listener_far_model_scores > 0.5)/len(imaginative_listener_far_model_scores))\n",
    "        close_accuracies.append(np.mean(imaginative_listener_close_model_scores))\n",
    "        split_accuracies.append(np.mean(imaginative_listener_split_model_scores))\n",
    "        far_accuracies.append(np.mean(imaginative_listener_far_model_scores))\n",
    "        \n",
    "        print(\"Most recent stats:\")\n",
    "        print(\"agg acc:\", aggregate_accuracies[-1])\n",
    "        print(\"clo acc:\", close_accuracies[-1])\n",
    "        print(\"spl acc:\", split_accuracies[-1])\n",
    "        print(\"far acc:\", far_accuracies[-1])\n",
    "        print(\"agg cor:\", aggregate_correlations[-1])\n",
    "        print(\"clo cor:\", close_correlations[-1])\n",
    "        print(\"spl cor:\", split_correlations[-1])\n",
    "        print(\"far cor:\", far_correlations[-1])\n",
    "        \n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sample #0\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.98516954890258\n",
      "clo acc: 18.27353323876809\n",
      "spl acc: 19.544536012224782\n",
      "far acc: 34.14159079769889\n",
      "agg cor: (-0.886422302978764, 4.250960310734327e-178)\n",
      "clo cor: (-0.455535609378521, 2.0635307187084423e-28)\n",
      "spl cor: (-0.5473674197436782, 1.3343968892457512e-42)\n",
      "far cor: (-0.8657290229509013, 3.1337385241772896e-160)\n",
      "Evaluating sample #1\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.211091965944536\n",
      "clo acc: 18.65899781108387\n",
      "spl acc: 19.767035392086786\n",
      "far acc: 34.21259842311515\n",
      "agg cor: (-0.8860109120142069, 1.0393073393501362e-177)\n",
      "clo cor: (-0.44432579193215566, 5.887339051429764e-27)\n",
      "spl cor: (-0.5267565591108372, 4.9684543265154734e-39)\n",
      "far cor: (-0.8675670970509768, 1.079527020742103e-161)\n",
      "Evaluating sample #2\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.95348429830869\n",
      "clo acc: 18.437027023551213\n",
      "spl acc: 19.35961898023499\n",
      "far acc: 34.067678865462305\n",
      "agg cor: (-0.8919397009031778, 1.8685858962595625e-183)\n",
      "clo cor: (-0.4667281491674002, 6.407980536865597e-30)\n",
      "spl cor: (-0.5717604401511618, 3.6777693898206863e-47)\n",
      "far cor: (-0.8686362282684238, 1.4867365072500277e-162)\n",
      "Evaluating sample #3\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.018430904966912\n",
      "clo acc: 18.49341611855365\n",
      "spl acc: 19.4753261426775\n",
      "far acc: 34.09191124694347\n",
      "agg cor: (-0.8866139971776391, 2.7993650643129003e-178)\n",
      "clo cor: (-0.43810811058861493, 3.581899902245579e-26)\n",
      "spl cor: (-0.5296433756282287, 1.624662845037862e-39)\n",
      "far cor: (-0.8647559216076199, 1.8270776453110162e-159)\n",
      "Evaluating sample #4\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.17482971481473\n",
      "clo acc: 18.62743453645803\n",
      "spl acc: 19.752563626397155\n",
      "far acc: 34.14945435477963\n",
      "agg cor: (-0.8894263476542338, 5.585736691209525e-181)\n",
      "clo cor: (-0.45758906376919695, 1.1018524984903104e-28)\n",
      "spl cor: (-0.5325362340054747, 5.242969797755635e-40)\n",
      "far cor: (-0.869522995700688, 2.8335708940723594e-163)\n",
      "Evaluating sample #5\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.143522513533853\n",
      "clo acc: 18.643209041814377\n",
      "spl acc: 19.732187550885364\n",
      "far acc: 34.06440540427714\n",
      "agg cor: (-0.8811402706142353, 3.1832120315640084e-173)\n",
      "clo cor: (-0.4513571761678967, 7.3012410470162385e-28)\n",
      "spl cor: (-0.5007576193660417, 7.324464823278248e-35)\n",
      "far cor: (-0.8612623408930862, 9.16923335417871e-157)\n",
      "Evaluating sample #6\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.06136433254021\n",
      "clo acc: 18.56301687867534\n",
      "spl acc: 19.482940637388445\n",
      "far acc: 34.14122255837141\n",
      "agg cor: (-0.8828030354822461, 9.859024596492022e-175)\n",
      "clo cor: (-0.4389762719390835, 2.7898971710967474e-26)\n",
      "spl cor: (-0.529100039751234, 2.0067346509033875e-39)\n",
      "far cor: (-0.8659216681301237, 2.2068141227299776e-160)\n",
      "Evaluating sample #7\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.9379978094873\n",
      "clo acc: 18.382157579668977\n",
      "spl acc: 19.335616835781217\n",
      "far acc: 34.09880858608765\n",
      "agg cor: (-0.8858832216885367, 1.3707229566334728e-177)\n",
      "clo cor: (-0.4398237282512436, 2.1844838924650963e-26)\n",
      "spl cor: (-0.5283483825166942, 2.686037528842471e-39)\n",
      "far cor: (-0.8721234305787758, 2.0436151820523473e-165)\n",
      "Evaluating sample #8\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.076479484977696\n",
      "clo acc: 18.52792076547755\n",
      "spl acc: 19.65772880690549\n",
      "far acc: 34.0518591217395\n",
      "agg cor: (-0.8861779195808417, 7.232834278650833e-178)\n",
      "clo cor: (-0.4560009902923457, 1.7906809857010429e-28)\n",
      "spl cor: (-0.5125048638174236, 1.0609677577036421e-36)\n",
      "far cor: (-0.864174951180753, 5.200680015809707e-159)\n",
      "Evaluating sample #9\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.046209328341682\n",
      "clo acc: 18.429641808519204\n",
      "spl acc: 19.693467715322047\n",
      "far acc: 34.02026095170745\n",
      "agg cor: (-0.881236884541505, 2.6049799234726472e-173)\n",
      "clo cor: (-0.42574145054982565, 1.1653168048128728e-24)\n",
      "spl cor: (-0.5195249596346924, 7.798792194683714e-38)\n",
      "far cor: (-0.8642056203554739, 4.921872349097669e-159)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_imaginative_listener_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../results/imaginative_listener_assessment.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8857654592635387"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['aggregate_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.225927799225445]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.50006086024096]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.470457996575014]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.710338275301137]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8799177945947197, 1.4376357425904765e-168)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.4409533567945598, 5.226923223263904e-26)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8577761621065179, 5.865956224847408e-151)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.5079681530415953, 2.896292325793216e-35)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Literal Listener\n",
    "# -----------------------------------------\n",
    "# TODO: FILL IN PARAMETERS \n",
    "def literal_listener_experiment(train=False, epochs=5, embed_dim = 100, hidden_dim = 100, color_dim= 54, model_file=\"../model/literal_listener_5epoch-2.params\"):\n",
    "\n",
    "    # Initializing featurizers\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer) # Use with parameter files that end in `endings_tkn`\n",
    "    # caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.WhitespaceTokenizer) # Use with parameter files don't\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi) # target function is initialized by default\n",
    "\n",
    "    print(\"Initializing model\")\n",
    "    model = LiteralListener(CaptionEncoder, num_epochs = epochs)\n",
    "    model.init_model(embed_dim = embed_dim, hidden_dim = hidden_dim, vocab_size = feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                 color_dim = color_dim)\n",
    "\n",
    "    print(model_file)\n",
    "    model.load_model(model_file)\n",
    "\n",
    "    # convert the model output to a score for that particular round\n",
    "    print(\"Evaluating model\")\n",
    "    output_to_score = lambda model_outputs, targets: np.exp(model_outputs[np.arange(len(model_outputs)), targets]) # get the model's predicted probablity at each target index and use that as the score\n",
    "    my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "    return evaluate_model(test_data_synth, feature_handler, model, output_to_score, my_score_model, accuracy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume pragmatic will either be similar or need its own type of thing\n",
    "def evaluate_literal_listener_samples():\n",
    "    model_directory = \"../literal_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating Literal Listener #{}\".format(i))\n",
    "        _, listener_eval = literal_listener_experiment(model_file=\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        true_scores = listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        model_scores = listener_eval.groupby('gameid').model_scores.mean()\n",
    "        true_scores_composite = composite_score(listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(model_scores, true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        aggregate_accuracies.append(sum(listener_eval.model_scores > 0.5)/len(listener_eval.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        listener_close = listener_eval[listener_eval.condition == \"close\"]\n",
    "        listener_split = listener_eval[listener_eval.condition == \"split\"]\n",
    "        listener_far =   listener_eval[listener_eval.condition == \"far\"]\n",
    "\n",
    "        listener_close_true_scores =  listener_close.groupby('gameid').numOutcome.mean()\n",
    "        listener_close_model_scores = listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_split_true_scores =  listener_split.groupby('gameid').numOutcome.mean()\n",
    "        listener_split_model_scores = listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_far_true_scores =  listener_far.groupby('gameid').numOutcome.mean()\n",
    "        listener_far_model_scores = listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        listener_close_composite = composite_score(listener_close)\n",
    "        listener_split_composite = composite_score(listener_split)\n",
    "        listener_far_composite   = composite_score(listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(listener_close_composite, listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(listener_split_composite, listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(listener_far_composite,     listener_far_model_scores))\n",
    "\n",
    "        close_accuracies.append(sum(listener_close_model_scores > 0.5)/len(listener_close_model_scores))\n",
    "        split_accuracies.append(sum(listener_split_model_scores > 0.5)/len(listener_split_model_scores))\n",
    "        far_accuracies.append(sum(  listener_far_model_scores > 0.5)/len(listener_far_model_scores))\n",
    "\n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Literal Listener #0\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_0.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #1\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_1.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #2\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_2.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #3\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_3.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #4\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_4.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #5\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_5.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #6\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_6.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #7\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_7.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #8\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_8.params\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Evaluating Literal Listener #9\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "../literal_listener_samples/sample_9.params\n",
      "Evaluating model\n",
      "Got here to composite score\n"
     ]
    }
   ],
   "source": [
    "lit_list_results = evaluate_literal_listener_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.46049242424242426,\n",
       "  0.4615530303030303,\n",
       "  0.45943181818181816,\n",
       "  0.46018939393939395,\n",
       "  0.4612878787878788,\n",
       "  0.45943181818181816,\n",
       "  0.4622727272727273,\n",
       "  0.4640530303030303,\n",
       "  0.45928030303030304,\n",
       "  0.46291666666666664],\n",
       " 'aggregate_correlations': [(0.9551759148646606, 3.0935791851169376e-280),\n",
       "  (0.9568476244064827, 1.7621957268376714e-284),\n",
       "  (0.9603190673145864, 7.374406257773924e-294),\n",
       "  (0.9574546888418075, 4.602225052553829e-286),\n",
       "  (0.9577112364008573, 9.704974230231723e-287),\n",
       "  (0.9526759938115862, 3.502564978285354e-274),\n",
       "  (0.9572465172587161, 1.6159210417650658e-285),\n",
       "  (0.9620378670937882, 8.113979043277967e-299),\n",
       "  (0.9534726907653601, 4.4809420710264456e-276),\n",
       "  (0.9591990326239181, 9.599581623980341e-291)],\n",
       " 'close_accuracies': [0.38825757575757575,\n",
       "  0.4147727272727273,\n",
       "  0.38446969696969696,\n",
       "  0.3996212121212121,\n",
       "  0.39015151515151514,\n",
       "  0.3693181818181818,\n",
       "  0.3996212121212121,\n",
       "  0.42045454545454547,\n",
       "  0.38446969696969696,\n",
       "  0.4034090909090909],\n",
       " 'close_correlations': [(0.855525213572353, 1.7410189542019432e-152),\n",
       "  (0.8691192042449603, 6.036637884990569e-163),\n",
       "  (0.8772251833362054, 9.298948468391645e-170),\n",
       "  (0.8634652336927975, 1.8543481012862976e-158),\n",
       "  (0.8689150021400572, 8.840674750647576e-163),\n",
       "  (0.8494152250813579, 3.965321547293733e-148),\n",
       "  (0.8625988103758551, 8.670229318031713e-158),\n",
       "  (0.8752687942627781, 4.529109199135237e-168),\n",
       "  (0.8479962924697155, 3.824404682359527e-147),\n",
       "  (0.8771625906591279, 1.054077009969399e-169)],\n",
       " 'far_accuracies': [0.4696969696969697,\n",
       "  0.4810606060606061,\n",
       "  0.4696969696969697,\n",
       "  0.4753787878787879,\n",
       "  0.48484848484848486,\n",
       "  0.4753787878787879,\n",
       "  0.4734848484848485,\n",
       "  0.4734848484848485,\n",
       "  0.4791666666666667,\n",
       "  0.4715909090909091],\n",
       " 'far_correlations': [(0.9476143513266879, 7.18848800267197e-263),\n",
       "  (0.9470192703211613, 1.2947327175152507e-261),\n",
       "  (0.9488472839030531, 1.614301839007367e-265),\n",
       "  (0.9482862272574941, 2.638285307769947e-264),\n",
       "  (0.9436172426980212, 1.0530496800477131e-254),\n",
       "  (0.9432168247909891, 6.417906778197712e-254),\n",
       "  (0.9474363668726197, 1.7127432615804325e-262),\n",
       "  (0.9481268629690013, 5.800902343390754e-264),\n",
       "  (0.9459012047962954, 2.706464253851785e-259),\n",
       "  (0.9469762642213896, 1.5935096246600806e-261)],\n",
       " 'split_accuracies': [0.4734848484848485,\n",
       "  0.4696969696969697,\n",
       "  0.4734848484848485,\n",
       "  0.48484848484848486,\n",
       "  0.48484848484848486,\n",
       "  0.4734848484848485,\n",
       "  0.4734848484848485,\n",
       "  0.4772727272727273,\n",
       "  0.4696969696969697,\n",
       "  0.4810606060606061],\n",
       " 'split_correlations': [(0.8893009351888765, 7.396629132695641e-181),\n",
       "  (0.8832580301709915, 3.774956199956075e-175),\n",
       "  (0.8989264543215286, 1.1340346717061795e-190),\n",
       "  (0.894636990539324, 3.5133229552145458e-186),\n",
       "  (0.8884317676328783, 5.13102307741107e-180),\n",
       "  (0.867628065830485, 9.6457508257869e-162),\n",
       "  (0.894595702900694, 3.8725613378922735e-186),\n",
       "  (0.9047277722382036, 4.4538891394010366e-197),\n",
       "  (0.8831824777767148, 4.4285599004887074e-175),\n",
       "  (0.8941360470588509, 1.141617441130678e-185)]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/literal_listener_assessment.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lit_list_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.46049242424242426,\n",
       "  0.4615530303030303,\n",
       "  0.45943181818181816,\n",
       "  0.46018939393939395,\n",
       "  0.4612878787878788,\n",
       "  0.45943181818181816,\n",
       "  0.4622727272727273,\n",
       "  0.4640530303030303,\n",
       "  0.45928030303030304,\n",
       "  0.46291666666666664],\n",
       " 'aggregate_correlations': [(0.9551759148646606, 3.0935791851169376e-280),\n",
       "  (0.9568476244064827, 1.7621957268376714e-284),\n",
       "  (0.9603190673145864, 7.374406257773924e-294),\n",
       "  (0.9574546888418075, 4.602225052553829e-286),\n",
       "  (0.9577112364008573, 9.704974230231723e-287),\n",
       "  (0.9526759938115862, 3.502564978285354e-274),\n",
       "  (0.9572465172587161, 1.6159210417650658e-285),\n",
       "  (0.9620378670937882, 8.113979043277967e-299),\n",
       "  (0.9534726907653601, 4.4809420710264456e-276),\n",
       "  (0.9591990326239181, 9.599581623980341e-291)],\n",
       " 'close_accuracies': [0.38825757575757575,\n",
       "  0.4147727272727273,\n",
       "  0.38446969696969696,\n",
       "  0.3996212121212121,\n",
       "  0.39015151515151514,\n",
       "  0.3693181818181818,\n",
       "  0.3996212121212121,\n",
       "  0.42045454545454547,\n",
       "  0.38446969696969696,\n",
       "  0.4034090909090909],\n",
       " 'close_correlations': [(0.855525213572353, 1.7410189542019432e-152),\n",
       "  (0.8691192042449603, 6.036637884990569e-163),\n",
       "  (0.8772251833362054, 9.298948468391645e-170),\n",
       "  (0.8634652336927975, 1.8543481012862976e-158),\n",
       "  (0.8689150021400572, 8.840674750647576e-163),\n",
       "  (0.8494152250813579, 3.965321547293733e-148),\n",
       "  (0.8625988103758551, 8.670229318031713e-158),\n",
       "  (0.8752687942627781, 4.529109199135237e-168),\n",
       "  (0.8479962924697155, 3.824404682359527e-147),\n",
       "  (0.8771625906591279, 1.054077009969399e-169)],\n",
       " 'far_accuracies': [0.4696969696969697,\n",
       "  0.4810606060606061,\n",
       "  0.4696969696969697,\n",
       "  0.4753787878787879,\n",
       "  0.48484848484848486,\n",
       "  0.4753787878787879,\n",
       "  0.4734848484848485,\n",
       "  0.4734848484848485,\n",
       "  0.4791666666666667,\n",
       "  0.4715909090909091],\n",
       " 'far_correlations': [(0.9476143513266879, 7.18848800267197e-263),\n",
       "  (0.9470192703211613, 1.2947327175152507e-261),\n",
       "  (0.9488472839030531, 1.614301839007367e-265),\n",
       "  (0.9482862272574941, 2.638285307769947e-264),\n",
       "  (0.9436172426980212, 1.0530496800477131e-254),\n",
       "  (0.9432168247909891, 6.417906778197712e-254),\n",
       "  (0.9474363668726197, 1.7127432615804325e-262),\n",
       "  (0.9481268629690013, 5.800902343390754e-264),\n",
       "  (0.9459012047962954, 2.706464253851785e-259),\n",
       "  (0.9469762642213896, 1.5935096246600806e-261)],\n",
       " 'split_accuracies': [0.4734848484848485,\n",
       "  0.4696969696969697,\n",
       "  0.4734848484848485,\n",
       "  0.48484848484848486,\n",
       "  0.48484848484848486,\n",
       "  0.4734848484848485,\n",
       "  0.4734848484848485,\n",
       "  0.4772727272727273,\n",
       "  0.4696969696969697,\n",
       "  0.4810606060606061],\n",
       " 'split_correlations': [(0.8893009351888765, 7.396629132695641e-181),\n",
       "  (0.8832580301709915, 3.774956199956075e-175),\n",
       "  (0.8989264543215286, 1.1340346717061795e-190),\n",
       "  (0.894636990539324, 3.5133229552145458e-186),\n",
       "  (0.8884317676328783, 5.13102307741107e-180),\n",
       "  (0.867628065830485, 9.6457508257869e-162),\n",
       "  (0.894595702900694, 3.8725613378922735e-186),\n",
       "  (0.9047277722382036, 4.4538891394010366e-197),\n",
       "  (0.8831824777767148, 4.4285599004887074e-175),\n",
       "  (0.8941360470588509, 1.141617441130678e-185)]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume pragmatic will either be similar or need its own type of thing\n",
    "def evaluate_literal_listener_samples():\n",
    "    model_directory = \"../literal_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating Literal Listener #{}\".format(i))\n",
    "        _, listener_eval = literal_listener_experiment(model_file=\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        true_scores = listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        model_scores = listener_eval.groupby('gameid').model_scores.mean()\n",
    "        true_scores_composite = composite_score(listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(model_scores, true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        aggregate_accuracies.append(sum(listener_eval.model_scores > 0.5)/len(listener_eval.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        listener_close = listener_eval[listener_eval.condition == \"close\"]\n",
    "        listener_split = listener_eval[listener_eval.condition == \"split\"]\n",
    "        listener_far =   listener_eval[listener_eval.condition == \"far\"]\n",
    "\n",
    "        listener_close_true_scores =  listener_close.groupby('gameid').numOutcome.mean()\n",
    "        listener_close_model_scores = listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_split_true_scores =  listener_split.groupby('gameid').numOutcome.mean()\n",
    "        listener_split_model_scores = listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_far_true_scores =  listener_far.groupby('gameid').numOutcome.mean()\n",
    "        listener_far_model_scores = listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        listener_close_composite = composite_score(listener_close)\n",
    "        listener_split_composite = composite_score(listener_split)\n",
    "        listener_far_composite   = composite_score(listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(listener_close_composite, listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(listener_split_composite, listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(listener_far_composite,     listener_far_model_scores))\n",
    "\n",
    "        close_accuracies.append(sum(listener_close_model_scores > 0.5)/len(listener_close_model_scores))\n",
    "        split_accuracies.append(sum(listener_split_model_scores > 0.5)/len(listener_split_model_scores))\n",
    "        far_accuracies.append(sum(  listener_far_model_scores > 0.5)/len(listener_far_model_scores))\n",
    "\n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    #a = 1.0 * np.array(data)\n",
    "    a = data\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    print(\"${:.4f}\\pm{:.4f}$\".format(m, h))\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9467041899156712, 0.9453345265907224, 0.94807385324062)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([l[0] for l in lit_list_results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001369663324948811"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9467041899156712-0.9453345265907224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9467041899156712-0.001369663324948811"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9551759148646606, 3.0935791851169376e-280),\n",
       " (0.9568476244064827, 1.7621957268376714e-284),\n",
       " (0.9603190673145864, 7.374406257773924e-294),\n",
       " (0.9574546888418075, 4.602225052553829e-286),\n",
       " (0.9577112364008573, 9.704974230231723e-287),\n",
       " (0.9526759938115862, 3.502564978285354e-274),\n",
       " (0.9572465172587161, 1.6159210417650658e-285),\n",
       " (0.9620378670937882, 8.113979043277967e-299),\n",
       " (0.9534726907653601, 4.4809420710264456e-276),\n",
       " (0.9591990326239181, 9.599581623980341e-291)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lit_list_results['aggregate_correlations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46109090909090905, 0.4599297914836187, 0.4622520266981994)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(lit_list_results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001161117607290374"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4599297914836187-0.46109090909090905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.4599297914836187-0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8663899276716822, -0.8686320928835145, -0.8641477624598499)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([l[0] for l in results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008684566179368414"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.8663899276716822--0.8686320928835145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7350220205551967"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.8663899276716822-0.008684566179368414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.060857990181823, 23.994688173655458, 24.12702780670819)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06616981652636511"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.060857990181823-23.994688173655458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.12702780670819"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24.060857990181823+0.06616981652636511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prag_list_results = None\n",
    "with open(\"../results/pragmatic_listener_assessment.pkl\", \"rb\") as file:\n",
    "    prag_list_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.4533333333333333,\n",
       "  0.4526136363636364,\n",
       "  0.4530681818181818,\n",
       "  0.4536742424242424,\n",
       "  0.4531439393939394,\n",
       "  0.45325757575757575,\n",
       "  0.4536742424242424,\n",
       "  0.4530681818181818,\n",
       "  0.45268939393939395,\n",
       "  0.4520075757575758],\n",
       " 'aggregate_correlations': [(0.9615612280860988, 2.027065475884201e-297),\n",
       "  (0.9618056146561487, 3.91275795421677e-298),\n",
       "  (0.9617898446679253, 4.352331620136946e-298),\n",
       "  (0.9618575041863672, 2.7555019753713967e-298),\n",
       "  (0.9615458400800124, 2.2474727470917922e-297),\n",
       "  (0.9617135918003048, 7.278264227716953e-298),\n",
       "  (0.9619005374934682, 2.059438343024509e-298),\n",
       "  (0.9616903550580581, 8.511110396845046e-298),\n",
       "  (0.9616526527680964, 1.0968855063184333e-297),\n",
       "  (0.9616802273009595, 9.111561381510886e-298)],\n",
       " 'close_accuracies': [0.3958333333333333,\n",
       "  0.3958333333333333,\n",
       "  0.3977272727272727,\n",
       "  0.3996212121212121,\n",
       "  0.3958333333333333,\n",
       "  0.3939393939393939,\n",
       "  0.3996212121212121,\n",
       "  0.3939393939393939,\n",
       "  0.3958333333333333,\n",
       "  0.3958333333333333],\n",
       " 'close_correlations': [(0.8843297609118992, 3.872164319504565e-176),\n",
       "  (0.8848152723866364, 1.3699707986864544e-176),\n",
       "  (0.884273514628581, 4.366154929409032e-176),\n",
       "  (0.8852024247153802, 5.962476330012655e-177),\n",
       "  (0.8845804980946806, 2.2655190787870958e-176),\n",
       "  (0.885533359474058, 2.9212596123382614e-177),\n",
       "  (0.8845030125012531, 2.6740129980855973e-176),\n",
       "  (0.8836033953513593, 1.8167030861638095e-175),\n",
       "  (0.8847657641805122, 1.523414317665323e-176),\n",
       "  (0.8836154266152582, 1.7709275512704422e-175)],\n",
       " 'far_accuracies': [0.4791666666666667,\n",
       "  0.4772727272727273,\n",
       "  0.4810606060606061,\n",
       "  0.48484848484848486,\n",
       "  0.4810606060606061,\n",
       "  0.4810606060606061,\n",
       "  0.4772727272727273,\n",
       "  0.4791666666666667,\n",
       "  0.4791666666666667,\n",
       "  0.4791666666666667],\n",
       " 'far_correlations': [(0.9483566745606177, 1.860876599935368e-264),\n",
       "  (0.9486021133031725, 5.493672621543954e-265),\n",
       "  (0.9486098180776468, 5.286735623781734e-265),\n",
       "  (0.948290673795137, 2.5808275567760673e-264),\n",
       "  (0.9483719907982654, 1.724759552066711e-264),\n",
       "  (0.9488135565629366, 1.9112112962024947e-265),\n",
       "  (0.9487779299411102, 2.2840618096050038e-265),\n",
       "  (0.9485599516132441, 6.777451693303814e-265),\n",
       "  (0.9485193563703943, 8.294858989367822e-265),\n",
       "  (0.9486529539267797, 4.263660905284032e-265)],\n",
       " 'split_accuracies': [0.4583333333333333,\n",
       "  0.4602272727272727,\n",
       "  0.4564393939393939,\n",
       "  0.45454545454545453,\n",
       "  0.4583333333333333,\n",
       "  0.4564393939393939,\n",
       "  0.4602272727272727,\n",
       "  0.4602272727272727,\n",
       "  0.4583333333333333,\n",
       "  0.4583333333333333],\n",
       " 'split_correlations': [(0.9043391371918844, 1.231954585039109e-196),\n",
       "  (0.9045086724165378, 7.90817678217521e-197),\n",
       "  (0.9045104181465087, 7.872127210199812e-197),\n",
       "  (0.9050367711212649, 1.9772739881878502e-197),\n",
       "  (0.9042874883555962, 1.4098528863432917e-196),\n",
       "  (0.9044775695172081, 8.578724866430755e-197),\n",
       "  (0.90449790978604, 8.134085906847147e-197),\n",
       "  (0.9054372874656674, 6.872846520928148e-198),\n",
       "  (0.904899646253739, 2.836102987932115e-197),\n",
       "  (0.90451300512035, 7.819006541732408e-197)]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prag_list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.4531\\pm0.0004$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.45305303030303035, 0.4526898920387431, 0.4534161685673176)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval(prag_list_results['aggregate_accuracies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$0.9486\\pm0.0001$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9485555018949304, 0.9484303757518484, 0.9486806280380125)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_confidence_interval([l[0] for l in prag_list_results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

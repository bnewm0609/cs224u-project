{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can use packages from parent directory\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code copied from example experiments.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from monroe_data import MonroeData, MonroeDataEntry, Color # last two for reading pkl file\n",
    "import caption_featurizers\n",
    "from color_featurizers import ColorFeaturizer, color_phi_fourier\n",
    "from models import LiteralListener, LiteralSpeaker, ImaginativeListener, PragmaticListener, CaptionEncoder, CaptionGenerator, ColorGenerator\n",
    "from evaluation import score_model, delta_e_dist, Speaker, Score\n",
    "from experiment import FeatureHandler, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import experiment\n",
    "importlib.reload(experiment)\n",
    "from experiment import FeatureHandler, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix=\"../\"\n",
    "train_data = MonroeData(prefix + \"data/csv/train_corpus_monroe.csv\", prefix + \"data/entries/train_entries_monroe.pkl\")\n",
    "dev_data_synth  = MonroeData(prefix + \"data/csv/dev_corpus_synth_10fold.csv\", prefix + \"data/entries/dev_corpus_synth_10fold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_synth  = MonroeData(prefix + \"data/csv/test_corpus_synth_10fold.csv\", prefix + \"data/entries/test_corpus_synth_10fold.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_score(eval_df, speaker=\"gameid\"):\n",
    "    mean_scores = eval_df.groupby(speaker).numOutcome.mean()\n",
    "    mean_numCleanWords = eval_df.groupby(speaker).numCleanWords.mean()\n",
    "    mean_clkTime = eval_df.groupby(speaker).clkTime.mean()\n",
    "    true_scores = mean_scores / mean_clkTime / mean_numCleanWords\n",
    "    max_score = true_scores.max()\n",
    "    true_scores /= max_score # normalize the scores\n",
    "    return true_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Imaginative Listener\n",
    "def imaginative_listener(model_file=\"../model/imaginative_listener_with_distractors_linear100hd5epoch_GLOVE_MSE.params\"):\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer)\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "\n",
    "    def target_color_target(data_entry):\n",
    "        return np.array(data_entry.colors[0].rgb_norm)\n",
    "\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi, target_fn=target_color_target,\n",
    "                                randomized_colors=False) #using TEST data now :) \n",
    "\n",
    "    print(\"Obtaining training features\") # get features even if you're runnning the pretrained model for example\n",
    "    #train_features = feature_handler.train_features()\n",
    "    #train_targets = feature_handler.train_targets()\n",
    "\n",
    "    imaginative_model = ImaginativeListener(ColorGenerator, criterion=torch.nn.CosineEmbeddingLoss,\n",
    "                            optimizer=torch.optim.Adam, lr=0.004, num_epochs=5)\n",
    "\n",
    "    # Creating model\n",
    "    MSELossSum = lambda: nn.MSELoss(reduction='sum') # sorry for this ugliness..... but this is me passing a parameter to the loss func\n",
    "    imaginative_model = ImaginativeListener(ColorGenerator, criterion=MSELossSum,\n",
    "                                optimizer=torch.optim.Adam, lr=0.001, num_epochs=5, use_color=True)\n",
    "    imaginative_model.init_model(embed_dim=100, hidden_dim=50, vocab_size=feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                    color_in_dim=54, color_hidden_dim=50, weight_matrix=caption_featurizers.get_pretrained_glove(feature_handler.caption_featurizer.caption_indexer.idx2word.items(), 100, prefix=True))\n",
    "\n",
    "    imaginative_model.load_model(model_file)\n",
    "        \n",
    "    print(\"Evaluating model\")\n",
    "    output_to_score_de = lambda outputs, targets: np.array([delta_e_dist(outputs[i], targets[i]) for i in range(len(targets))])\n",
    "    # we want to score based on the model's predictions at the TARGET indices not listener clicked indices,\n",
    "    # so we change the feature_handler's target function to do that:\n",
    "    my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "    result = evaluate_model(test_data_synth, feature_handler, imaginative_model, output_to_score_de, my_score_model, accuracy=False)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_imaginative_listener_samples():\n",
    "    model_directory = \"../imaginative_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        print(\"Evaluating sample #{}\".format(i))\n",
    "        _, imaginative_listener_eval = imaginative_listener(\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        il_true_scores = imaginative_listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        il_model_scores = imaginative_listener_eval.groupby('gameid').model_scores.mean()\n",
    "        il_true_scores_composite = composite_score(imaginative_listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(il_model_scores, il_true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        #aggregate_accuracies.append(sum(imaginative_listener_eval.model_scores > 0.5)/len(imaginative_listener_eval.model_scores))\n",
    "        aggregate_accuracies.append(np.mean(imaginative_listener_eval.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        imaginative_listener_close = imaginative_listener_eval[imaginative_listener_eval.condition == \"close\"]\n",
    "        imaginative_listener_split = imaginative_listener_eval[imaginative_listener_eval.condition == \"split\"]\n",
    "        imaginative_listener_far = imaginative_listener_eval[imaginative_listener_eval.condition == \"far\"]\n",
    "\n",
    "        imaginative_listener_close_true_scores = imaginative_listener_close.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_close_model_scores = imaginative_listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        imaginative_listener_split_true_scores =  imaginative_listener_split.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_split_model_scores = imaginative_listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        imaginative_listener_far_true_scores =  imaginative_listener_far.groupby('gameid').numOutcome.mean()\n",
    "        imaginative_listener_far_model_scores = imaginative_listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        imaginative_listener_close_composite = composite_score(imaginative_listener_close)\n",
    "        imaginative_listener_split_composite = composite_score(imaginative_listener_split)\n",
    "        imaginative_listener_far_composite   = composite_score(imaginative_listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(imaginative_listener_close_composite, imaginative_listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(imaginative_listener_split_composite, imaginative_listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(imaginative_listener_far_composite, imaginative_listener_far_model_scores))\n",
    "\n",
    "    #     close_accuracies.append(sum(imaginative_listener_close_model_scores > 0.5)/len(imaginative_listener_close_model_scores))\n",
    "    #     split_accuracies.append(sum(imaginative_listener_split_model_scores > 0.5)/len(imaginative_listener_split_model_scores))\n",
    "    #     far_accuracies.append(sum(imaginative_listener_far_model_scores > 0.5)/len(imaginative_listener_far_model_scores))\n",
    "        close_accuracies.append(np.mean(imaginative_listener_close_model_scores))\n",
    "        split_accuracies.append(np.mean(imaginative_listener_split_model_scores))\n",
    "        far_accuracies.append(np.mean(imaginative_listener_far_model_scores))\n",
    "        \n",
    "        print(\"Most recent stats:\")\n",
    "        print(\"agg acc:\", aggregate_accuracies[-1])\n",
    "        print(\"clo acc:\", close_accuracies[-1])\n",
    "        print(\"spl acc:\", split_accuracies[-1])\n",
    "        print(\"far acc:\", far_accuracies[-1])\n",
    "        print(\"agg cor:\", aggregate_correlations[-1])\n",
    "        print(\"clo cor:\", close_correlations[-1])\n",
    "        print(\"spl cor:\", split_correlations[-1])\n",
    "        print(\"far cor:\", far_correlations[-1])\n",
    "        \n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating sample #0\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.98516954890258\n",
      "clo acc: 18.27353323876809\n",
      "spl acc: 19.544536012224782\n",
      "far acc: 34.14159079769889\n",
      "agg cor: (-0.886422302978764, 4.250960310734327e-178)\n",
      "clo cor: (-0.455535609378521, 2.0635307187084423e-28)\n",
      "spl cor: (-0.5473674197436782, 1.3343968892457512e-42)\n",
      "far cor: (-0.8657290229509013, 3.1337385241772896e-160)\n",
      "Evaluating sample #1\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.211091965944536\n",
      "clo acc: 18.65899781108387\n",
      "spl acc: 19.767035392086786\n",
      "far acc: 34.21259842311515\n",
      "agg cor: (-0.8860109120142069, 1.0393073393501362e-177)\n",
      "clo cor: (-0.44432579193215566, 5.887339051429764e-27)\n",
      "spl cor: (-0.5267565591108372, 4.9684543265154734e-39)\n",
      "far cor: (-0.8675670970509768, 1.079527020742103e-161)\n",
      "Evaluating sample #2\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.95348429830869\n",
      "clo acc: 18.437027023551213\n",
      "spl acc: 19.35961898023499\n",
      "far acc: 34.067678865462305\n",
      "agg cor: (-0.8919397009031778, 1.8685858962595625e-183)\n",
      "clo cor: (-0.4667281491674002, 6.407980536865597e-30)\n",
      "spl cor: (-0.5717604401511618, 3.6777693898206863e-47)\n",
      "far cor: (-0.8686362282684238, 1.4867365072500277e-162)\n",
      "Evaluating sample #3\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.018430904966912\n",
      "clo acc: 18.49341611855365\n",
      "spl acc: 19.4753261426775\n",
      "far acc: 34.09191124694347\n",
      "agg cor: (-0.8866139971776391, 2.7993650643129003e-178)\n",
      "clo cor: (-0.43810811058861493, 3.581899902245579e-26)\n",
      "spl cor: (-0.5296433756282287, 1.624662845037862e-39)\n",
      "far cor: (-0.8647559216076199, 1.8270776453110162e-159)\n",
      "Evaluating sample #4\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.17482971481473\n",
      "clo acc: 18.62743453645803\n",
      "spl acc: 19.752563626397155\n",
      "far acc: 34.14945435477963\n",
      "agg cor: (-0.8894263476542338, 5.585736691209525e-181)\n",
      "clo cor: (-0.45758906376919695, 1.1018524984903104e-28)\n",
      "spl cor: (-0.5325362340054747, 5.242969797755635e-40)\n",
      "far cor: (-0.869522995700688, 2.8335708940723594e-163)\n",
      "Evaluating sample #5\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.143522513533853\n",
      "clo acc: 18.643209041814377\n",
      "spl acc: 19.732187550885364\n",
      "far acc: 34.06440540427714\n",
      "agg cor: (-0.8811402706142353, 3.1832120315640084e-173)\n",
      "clo cor: (-0.4513571761678967, 7.3012410470162385e-28)\n",
      "spl cor: (-0.5007576193660417, 7.324464823278248e-35)\n",
      "far cor: (-0.8612623408930862, 9.16923335417871e-157)\n",
      "Evaluating sample #6\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.06136433254021\n",
      "clo acc: 18.56301687867534\n",
      "spl acc: 19.482940637388445\n",
      "far acc: 34.14122255837141\n",
      "agg cor: (-0.8828030354822461, 9.859024596492022e-175)\n",
      "clo cor: (-0.4389762719390835, 2.7898971710967474e-26)\n",
      "spl cor: (-0.529100039751234, 2.0067346509033875e-39)\n",
      "far cor: (-0.8659216681301237, 2.2068141227299776e-160)\n",
      "Evaluating sample #7\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 23.9379978094873\n",
      "clo acc: 18.382157579668977\n",
      "spl acc: 19.335616835781217\n",
      "far acc: 34.09880858608765\n",
      "agg cor: (-0.8858832216885367, 1.3707229566334728e-177)\n",
      "clo cor: (-0.4398237282512436, 2.1844838924650963e-26)\n",
      "spl cor: (-0.5283483825166942, 2.686037528842471e-39)\n",
      "far cor: (-0.8721234305787758, 2.0436151820523473e-165)\n",
      "Evaluating sample #8\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.076479484977696\n",
      "clo acc: 18.52792076547755\n",
      "spl acc: 19.65772880690549\n",
      "far acc: 34.0518591217395\n",
      "agg cor: (-0.8861779195808417, 7.232834278650833e-178)\n",
      "clo cor: (-0.4560009902923457, 1.7906809857010429e-28)\n",
      "spl cor: (-0.5125048638174236, 1.0609677577036421e-36)\n",
      "far cor: (-0.864174951180753, 5.200680015809707e-159)\n",
      "Evaluating sample #9\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Evaluating model\n",
      "Got here to composite score\n",
      "Most recent stats:\n",
      "agg acc: 24.046209328341682\n",
      "clo acc: 18.429641808519204\n",
      "spl acc: 19.693467715322047\n",
      "far acc: 34.02026095170745\n",
      "agg cor: (-0.881236884541505, 2.6049799234726472e-173)\n",
      "clo cor: (-0.42574145054982565, 1.1653168048128728e-24)\n",
      "spl cor: (-0.5195249596346924, 7.798792194683714e-38)\n",
      "far cor: (-0.8642056203554739, 4.921872349097669e-159)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_imaginative_listener_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../results/imaginative_listener_assessment.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8857654592635387"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['aggregate_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.225927799225445]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.50006086024096]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.470457996575014]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.710338275301137]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8799177945947197, 1.4376357425904765e-168)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.4409533567945598, 5.226923223263904e-26)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.8577761621065179, 5.865956224847408e-151)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "far_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.5079681530415953, 2.896292325793216e-35)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Literal Listener\n",
    "# -----------------------------------------\n",
    "# TODO: FILL IN PARAMETERS \n",
    "def literal_listener_experiment(train=False, evaluate=True, epochs=5, embed_dim = 100, hidden_dim = 100, color_dim= 54, model_file=\"../model/literal_listener_5epoch-2.params\"):\n",
    "\n",
    "    # Initializing featurizers\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer) # Use with parameter files that end in `endings_tkn`\n",
    "    # caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.WhitespaceTokenizer) # Use with parameter files don't\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi) # target function is initialized by default\n",
    "\n",
    "    print(\"Initializing model\")\n",
    "    model = LiteralListener(CaptionEncoder, num_epochs = epochs)\n",
    "    model.init_model(embed_dim = embed_dim, hidden_dim = hidden_dim, vocab_size = feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                 color_dim = color_dim)\n",
    "\n",
    "    model.load_model(model_file)\n",
    "\n",
    "    if not evaluate:\n",
    "        return model\n",
    "    else:\n",
    "        # convert the model output to a score for that particular round\n",
    "        print(\"Evaluating model\")\n",
    "        output_to_score = lambda model_outputs, targets: np.exp(model_outputs[np.arange(len(model_outputs)), targets]) # get the model's predicted probablity at each target index and use that as the score\n",
    "        my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "        return evaluate_model(test_data_synth, feature_handler, model, output_to_score, my_score_model, accuracy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume pragmatic will either be similar or need its own type of thing\n",
    "def evaluate_literal_listener_samples():\n",
    "    model_directory # FILL THIS IN = \"../literal_listener_samples\"\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        _, listener_eval = literal_listener(\"{}/sample_{}.params\".format(model_directory, i))\n",
    "        true_scores = listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        model_scores = listener_eval.groupby('gameid').model_scores.mean()\n",
    "        true_scores_composite = composite_score(listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(model_scores, true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        aggregate_accuracies.append(sum(listener_eval.model_scores > 0.5)/len(listener_eval.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        listener_close = listener_eval[listener_eval.condition == \"close\"]\n",
    "        listener_split = listener_eval[listener_eval.condition == \"split\"]\n",
    "        listener_far =   listener_eval[listener_eval.condition == \"far\"]\n",
    "\n",
    "        listener_close_true_scores =  listener_close.groupby('gameid').numOutcome.mean()\n",
    "        listener_close_model_scores = listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_split_true_scores =  listener_split.groupby('gameid').numOutcome.mean()\n",
    "        listener_split_model_scores = listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_far_true_scores =  listener_far.groupby('gameid').numOutcome.mean()\n",
    "        listener_far_model_scores = listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        listener_close_composite = composite_score(listener_close)\n",
    "        listener_split_composite = composite_score(listener_split)\n",
    "        listener_far_composite   = composite_score(listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(listener_close_composite, listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(listener_split_composite, listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(listener_far_composite,     listener_far_model_scores))\n",
    "\n",
    "        close_accuracies.append(sum(listener_close_model_scores > 0.5)/len(listener_close_model_scores))\n",
    "        split_accuracies.append(sum(listener_split_model_scores > 0.5)/len(listener_split_model_scores))\n",
    "        far_accuracies.append(sum(  listener_far_model_scores > 0.5)/len(listener_far_model_scores))\n",
    "\n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_speaker_experiment(train=False, epochs=5, color_in_dim = 54, color_dim = 100, embed_dim = 100, hidden_dim = 100, lr = 0.004, model_file=\"model/literal_speaker_5epoch.params\"):\n",
    "    # Initializing featurizers\n",
    "    print(\"Initializing featurizers\")\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer)  # we'll use the EndingTokenizer in order to have common training data, but should technically be WhitespaceTokenizer\n",
    "\n",
    "    color_phi = ColorFeaturizer(color_phi_fourier, \"hsv\", normalized=True) # speaker uses hsv \n",
    "    \n",
    "    # speaker's target is to predict tokens following the SOS token\n",
    "    def speaker_target(data_entry):\n",
    "        _, caption_ids = caption_phi.to_string_features(data_entry.caption) # this probably works...\n",
    "        target = caption_ids[1:]\n",
    "        return target\n",
    "\n",
    "    feature_handler = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi, target_fn=speaker_target, randomized_colors=False)\n",
    "\n",
    "    print(\"Obtaining training features\")\n",
    "    train_features = feature_handler.train_features()\n",
    "    train_targets = feature_handler.train_targets()\n",
    "\n",
    "    print(\"Initializing model\")\n",
    "    model = LiteralSpeaker(CaptionGenerator, optimizer=torch.optim.Adam, lr=lr, num_epochs=epochs)\n",
    "    #lit_speaker = Speaker(color_embed_dim, caption_phi.caption_indexer.size, embed_dim, hidden_dim)\n",
    "    model.init_model(color_in_dim=color_in_dim, color_dim=color_dim,\n",
    "                                  vocab_size=caption_phi.caption_indexer.size, embed_dim=embed_dim,\n",
    "                                 speaker_hidden_dim=hidden_dim)\n",
    "    if train:\n",
    "        print(\"Training model and saving to {}:\".format(model_file))\n",
    "        model.fit(train_features, train_targets)\n",
    "        model.save_model(model_file)\n",
    "    else:\n",
    "        print(\"Loading pretrained model\")\n",
    "        model.load_model(model_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pragmatic_listener(evaluate=True,\n",
    "        literal_model_file=\"../model/best_literal_listener.params\",\n",
    "        speaker_model_file=\"../model/literal_speaker_30epochGLOVE.params\",\n",
    "        alpha=0.5, # best\n",
    "        composite=True):\n",
    "    color_phi_listener = ColorFeaturizer(color_phi_fourier, \"rgb\", normalized=True)\n",
    "    color_phi_speaker = ColorFeaturizer(color_phi_fourier, \"hsv\", normalized=True)\n",
    "    caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer=caption_featurizers.EndingTokenizer)\n",
    "    feature_handler_listener = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi_listener)\n",
    "    feature_handler_speaker = FeatureHandler(train_data, test_data_synth, caption_phi, color_phi_speaker)\n",
    "    print(\"Loading literal listener\")\n",
    "    listener_model = literal_listener_experiment(train=False, evaluate=False, model_file=literal_model_file)\n",
    "    print(\"Loading literal speaker\")\n",
    "    speaker_model = literal_speaker_experiment(train=False, model_file=speaker_model_file)\n",
    "    pragmatic_model = PragmaticListener(listener_model, speaker_model,alpha=alpha)\n",
    "    if not evaluate:\n",
    "        return pragmatic_model\n",
    "    else:\n",
    "        output_to_score = lambda model_outputs, targets: np.exp(model_outputs[np.arange(len(model_outputs)), targets]) # get the model's predicted probablity at each target index and use that as the score\n",
    "        output_to_score_acc = lambda model_outputs, targets: np.argmax(model_outputs, axis=1) == targets \n",
    "        if composite:\n",
    "            my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True, score=Score.COMPOSITE)\n",
    "        else:\n",
    "            my_score_model = partial(score_model, speaker=Speaker.BY_GAME_ID_COND, return_df=True)\n",
    "        eval_p = evaluate_model(test_data_synth, feature_handler_listener, pragmatic_model, output_to_score,\n",
    "                              my_score_model, feature_handler_2=feature_handler_speaker) \n",
    "        eval_acc = evaluate_model(test_data_synth, feature_handler_listener, pragmatic_model, output_to_score_acc,\n",
    "                              my_score_model, feature_handler_2=feature_handler_speaker)\n",
    "        return (eval_p, eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pragmatic_listener_samples():\n",
    "    num_samples = 10\n",
    "    aggregate_correlations = []\n",
    "    close_correlations = []\n",
    "    split_correlations = []\n",
    "    far_correlations = []\n",
    "\n",
    "    aggregate_accuracies = []\n",
    "    close_accuracies = []\n",
    "    split_accuracies = []\n",
    "    far_accuracies = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        listener_eval, listener_eval_acc = pragmatic_listener()\n",
    "        _, listener_eval = listener_eval\n",
    "        listener_eval = listener_eval[0] # these are tuples for some reason...\n",
    "        _, listener_eval_acc = listener_eval_acc\n",
    "        listener_eval_acc = listener_eval_acc[0]\n",
    "        true_scores = listener_eval.groupby('gameid').numOutcome.mean()\n",
    "        model_scores = listener_eval.groupby('gameid').model_scores.mean()\n",
    "        true_scores_composite = composite_score(listener_eval)\n",
    "\n",
    "        aggregate_correlations.append(stats.pearsonr(model_scores, true_scores_composite))\n",
    "        # arbitrarily say we get it right if we assign a majority of the probability mass to it\n",
    "        aggregate_accuracies.append(sum(listener_eval_acc.model_scores)/len(listener_eval_acc.model_scores))\n",
    "\n",
    "        # separate out conditions\n",
    "        listener_close = listener_eval[listener_eval.condition == \"close\"]\n",
    "        listener_split = listener_eval[listener_eval.condition == \"split\"]\n",
    "        listener_far =   listener_eval[listener_eval.condition == \"far\"]\n",
    "        \n",
    "        listener_close_acc = listener_eval_acc[listener_eval_acc.condition == \"close\"]\n",
    "        listener_split_acc = listener_eval_acc[listener_eval_acc.condition == \"split\"]\n",
    "        listener_far_acc =   listener_eval_acc[listener_eval_acc.condition == \"far\"]\n",
    "\n",
    "        listener_close_true_scores =  listener_close.groupby('gameid').numOutcome.mean()\n",
    "        listener_close_model_scores = listener_close.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_split_true_scores =  listener_split.groupby('gameid').numOutcome.mean()\n",
    "        listener_split_model_scores = listener_split.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        listener_far_true_scores =  listener_far.groupby('gameid').numOutcome.mean()\n",
    "        listener_far_model_scores = listener_far.groupby('gameid').model_scores.mean()\n",
    "\n",
    "        # turn true scores to composite, gricean scores\n",
    "        listener_close_composite = composite_score(listener_close)\n",
    "        listener_split_composite = composite_score(listener_split)\n",
    "        listener_far_composite   = composite_score(listener_far)\n",
    "\n",
    "        close_correlations.append(stats.pearsonr(listener_close_composite, listener_close_model_scores))\n",
    "        split_correlations.append(stats.pearsonr(listener_split_composite, listener_split_model_scores))\n",
    "        far_correlations.append(stats.pearsonr(listener_far_composite,     listener_far_model_scores))\n",
    "\n",
    "        close_accuracies.append(sum(listener_close_acc.model_scores)/len(listener_close_acc.model_scores))\n",
    "        split_accuracies.append(sum(listener_split_acc.model_scores)/len(listener_split_acc.model_scores))\n",
    "        far_accuracies.append(sum(  listener_far_acc.model_scores)/len(listener_far_acc.model_scores))\n",
    "        \n",
    "        print({\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations})\n",
    "\n",
    "    return {\"aggregate_accuracies\": aggregate_accuracies,\n",
    "            \"close_accuracies\": close_accuracies,\n",
    "            \"split_accuracies\": split_accuracies,\n",
    "            \"far_accuracies\": far_accuracies,\n",
    "            \"aggregate_correlations\": aggregate_correlations,\n",
    "            \"close_correlations\":close_correlations,\n",
    "            \"far_correlations\":far_correlations,\n",
    "            \"split_correlations\": split_correlations}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4700757575757576\n",
      "Got here to composite score\n",
      "Accuracy: 0.46825757575757576\n",
      "{'aggregate_accuracies': [0.46825757575757576], 'close_accuracies': [0.4481818181818182], 'split_accuracies': [0.47306818181818183], 'far_accuracies': [0.48352272727272727], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4693939393939394\n",
      "Got here to composite score\n",
      "Accuracy: 0.4700378787878788\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788], 'close_accuracies': [0.4481818181818182, 0.4526136363636364], 'split_accuracies': [0.47306818181818183, 0.47306818181818183], 'far_accuracies': [0.48352272727272727, 0.4844318181818182], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4690909090909091\n",
      "Got here to composite score\n",
      "Accuracy: 0.46954545454545454\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.46920454545454543\n",
      "Got here to composite score\n",
      "Accuracy: 0.46893939393939393\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4697348484848485\n",
      "Got here to composite score\n",
      "Accuracy: 0.46856060606060607\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393, 0.46856060606060607], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727, 0.4501136363636364], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727, 0.4715909090909091], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818, 0.4839772727272727], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298), (0.9616145656342249, 1.4169314207903172e-297)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176), (0.8836896646063283, 1.5128152583785276e-175)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265), (0.9483663714703597, 1.7735072438456777e-264)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197), (0.9045139750003598, 7.799183247235733e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4691666666666667\n",
      "Got here to composite score\n",
      "Accuracy: 0.4693181818181818\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393, 0.46856060606060607, 0.4693181818181818], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727, 0.4501136363636364, 0.4510227272727273], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727, 0.4715909090909091, 0.4732954545454545], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818, 0.4839772727272727, 0.48363636363636364], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298), (0.9616145656342249, 1.4169314207903172e-297), (0.9617795779256101, 4.664601104499242e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176), (0.8836896646063283, 1.5128152583785276e-175), (0.8856842166049749, 2.1086473956538064e-177)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265), (0.9483663714703597, 1.7735072438456777e-264), (0.9483228566212399, 2.2004983659886287e-264)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197), (0.9045139750003598, 7.799183247235733e-197), (0.9050218820187866, 2.056307722754188e-197)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4693181818181818\n",
      "Got here to composite score\n",
      "Accuracy: 0.46950757575757573\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393, 0.46856060606060607, 0.4693181818181818, 0.46950757575757573], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727, 0.4501136363636364, 0.4510227272727273, 0.45125], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727, 0.4715909090909091, 0.4732954545454545, 0.4727272727272727], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818, 0.4839772727272727, 0.48363636363636364, 0.48454545454545456], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298), (0.9616145656342249, 1.4169314207903172e-297), (0.9617795779256101, 4.664601104499242e-298), (0.9617489822752973, 5.733814014436458e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176), (0.8836896646063283, 1.5128152583785276e-175), (0.8856842166049749, 2.1086473956538064e-177), (0.8835388035327452, 2.0833622144966806e-175)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265), (0.9483663714703597, 1.7735072438456777e-264), (0.9483228566212399, 2.2004983659886287e-264), (0.9482334168274038, 3.4263510849747037e-264)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197), (0.9045139750003598, 7.799183247235733e-197), (0.9050218820187866, 2.056307722754188e-197), (0.9047700995160637, 3.985666795639101e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4696969696969697\n",
      "Got here to composite score\n",
      "Accuracy: 0.4694318181818182\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393, 0.46856060606060607, 0.4693181818181818, 0.46950757575757573, 0.4694318181818182], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727, 0.4501136363636364, 0.4510227272727273, 0.45125, 0.4505681818181818], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727, 0.4715909090909091, 0.4732954545454545, 0.4727272727272727, 0.47295454545454546], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818, 0.4839772727272727, 0.48363636363636364, 0.48454545454545456, 0.4847727272727273], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298), (0.9616145656342249, 1.4169314207903172e-297), (0.9617795779256101, 4.664601104499242e-298), (0.9617489822752973, 5.733814014436458e-298), (0.9618894272250932, 2.2202909668708005e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176), (0.8836896646063283, 1.5128152583785276e-175), (0.8856842166049749, 2.1086473956538064e-177), (0.8835388035327452, 2.0833622144966806e-175), (0.8838613666176682, 1.0504438432585981e-175)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265), (0.9483663714703597, 1.7735072438456777e-264), (0.9483228566212399, 2.2004983659886287e-264), (0.9482334168274038, 3.4263510849747037e-264), (0.9485480472959544, 7.191240267457035e-265)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197), (0.9045139750003598, 7.799183247235733e-197), (0.9050218820187866, 2.056307722754188e-197), (0.9047700995160637, 3.985666795639101e-197), (0.9051216394560292, 1.5812168008043474e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.4696969696969697\n",
      "Got here to composite score\n",
      "Accuracy: 0.46912878787878787\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393, 0.46856060606060607, 0.4693181818181818, 0.46950757575757573, 0.4694318181818182, 0.46912878787878787], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727, 0.4501136363636364, 0.4510227272727273, 0.45125, 0.4505681818181818, 0.45227272727272727], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727, 0.4715909090909091, 0.4732954545454545, 0.4727272727272727, 0.47295454545454546, 0.47125], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818, 0.4839772727272727, 0.48363636363636364, 0.48454545454545456, 0.4847727272727273, 0.4838636363636364], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298), (0.9616145656342249, 1.4169314207903172e-297), (0.9617795779256101, 4.664601104499242e-298), (0.9617489822752973, 5.733814014436458e-298), (0.9618894272250932, 2.2202909668708005e-298), (0.9618884771641455, 2.2346131807101505e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176), (0.8836896646063283, 1.5128152583785276e-175), (0.8856842166049749, 2.1086473956538064e-177), (0.8835388035327452, 2.0833622144966806e-175), (0.8838613666176682, 1.0504438432585981e-175), (0.884643970686351, 1.9776691079184798e-176)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265), (0.9483663714703597, 1.7735072438456777e-264), (0.9483228566212399, 2.2004983659886287e-264), (0.9482334168274038, 3.4263510849747037e-264), (0.9485480472959544, 7.191240267457035e-265), (0.948408362248976, 1.4399561422360128e-264)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197), (0.9045139750003598, 7.799183247235733e-197), (0.9050218820187866, 2.056307722754188e-197), (0.9047700995160637, 3.985666795639101e-197), (0.9051216394560292, 1.5812168008043474e-197), (0.9050291823455431, 2.0171709690746114e-197)]}\n",
      "Loading literal listener\n",
      "Initializing featurizers\n",
      "Initializing model\n",
      "Loading literal speaker\n",
      "Initializing featurizers\n",
      "Obtaining training features\n",
      "Initializing model\n",
      "Loading pretrained model\n",
      "Got here to composite score\n",
      "Accuracy: 0.46912878787878787\n",
      "Got here to composite score\n",
      "Accuracy: 0.47015151515151515\n",
      "{'aggregate_accuracies': [0.46825757575757576, 0.4700378787878788, 0.46954545454545454, 0.46893939393939393, 0.46856060606060607, 0.4693181818181818, 0.46950757575757573, 0.4694318181818182, 0.46912878787878787, 0.47015151515151515], 'close_accuracies': [0.4481818181818182, 0.4526136363636364, 0.45125, 0.44977272727272727, 0.4501136363636364, 0.4510227272727273, 0.45125, 0.4505681818181818, 0.45227272727272727, 0.45227272727272727], 'split_accuracies': [0.47306818181818183, 0.47306818181818183, 0.47352272727272726, 0.4727272727272727, 0.4715909090909091, 0.4732954545454545, 0.4727272727272727, 0.47295454545454546, 0.47125, 0.4740909090909091], 'far_accuracies': [0.48352272727272727, 0.4844318181818182, 0.4838636363636364, 0.4843181818181818, 0.4839772727272727, 0.48363636363636364, 0.48454545454545456, 0.4847727272727273, 0.4838636363636364, 0.48409090909090907], 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298), (0.9619061957556335, 1.9820351122321373e-298), (0.9620535235642376, 7.294941110426085e-299), (0.9618692907112215, 2.5443736796406772e-298), (0.9616145656342249, 1.4169314207903172e-297), (0.9617795779256101, 4.664601104499242e-298), (0.9617489822752973, 5.733814014436458e-298), (0.9618894272250932, 2.2202909668708005e-298), (0.9618884771641455, 2.2346131807101505e-298), (0.9619051200765443, 1.9965235853990405e-298)], 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176), (0.8844433252787676, 3.0379928720675738e-176), (0.8848494340360462, 1.2731641597202667e-176), (0.8843677717008002, 3.570253149279174e-176), (0.8836896646063283, 1.5128152583785276e-175), (0.8856842166049749, 2.1086473956538064e-177), (0.8835388035327452, 2.0833622144966806e-175), (0.8838613666176682, 1.0504438432585981e-175), (0.884643970686351, 1.9776691079184798e-176), (0.8854108770437601, 3.8050704221121494e-177)], 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265), (0.9483323815390573, 2.099039933966994e-264), (0.9484359104002262, 1.2558740621017138e-264), (0.9486702457367623, 3.9112619634601055e-265), (0.9483663714703597, 1.7735072438456777e-264), (0.9483228566212399, 2.2004983659886287e-264), (0.9482334168274038, 3.4263510849747037e-264), (0.9485480472959544, 7.191240267457035e-265), (0.948408362248976, 1.4399561422360128e-264), (0.9487324135214734, 2.867558171015245e-265)], 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196), (0.9049705511607704, 2.3536836238675883e-197), (0.9052666791523398, 1.078642870171651e-197), (0.905127184938407, 1.5582786213791937e-197), (0.9045139750003598, 7.799183247235733e-197), (0.9050218820187866, 2.056307722754188e-197), (0.9047700995160637, 3.985666795639101e-197), (0.9051216394560292, 1.5812168008043474e-197), (0.9050291823455431, 2.0171709690746114e-197), (0.904212760791522, 1.7134416860121596e-196)]}\n",
      "CPU times: user 9h 9min 34s, sys: 34min 28s, total: 9h 44min 3s\n",
      "Wall time: 7h 39min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = evaluate_pragmatic_listener_samples()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aggregate_accuracies': [0.46825757575757576,\n",
       "  0.4700378787878788,\n",
       "  0.46954545454545454,\n",
       "  0.46893939393939393,\n",
       "  0.46856060606060607,\n",
       "  0.4693181818181818,\n",
       "  0.46950757575757573,\n",
       "  0.4694318181818182,\n",
       "  0.46912878787878787,\n",
       "  0.47015151515151515],\n",
       " 'aggregate_correlations': [(0.9617727835682962, 4.883427095399908e-298),\n",
       "  (0.9619061957556335, 1.9820351122321373e-298),\n",
       "  (0.9620535235642376, 7.294941110426085e-299),\n",
       "  (0.9618692907112215, 2.5443736796406772e-298),\n",
       "  (0.9616145656342249, 1.4169314207903172e-297),\n",
       "  (0.9617795779256101, 4.664601104499242e-298),\n",
       "  (0.9617489822752973, 5.733814014436458e-298),\n",
       "  (0.9618894272250932, 2.2202909668708005e-298),\n",
       "  (0.9618884771641455, 2.2346131807101505e-298),\n",
       "  (0.9619051200765443, 1.9965235853990405e-298)],\n",
       " 'close_accuracies': [0.4481818181818182,\n",
       "  0.4526136363636364,\n",
       "  0.45125,\n",
       "  0.44977272727272727,\n",
       "  0.4501136363636364,\n",
       "  0.4510227272727273,\n",
       "  0.45125,\n",
       "  0.4505681818181818,\n",
       "  0.45227272727272727,\n",
       "  0.45227272727272727],\n",
       " 'close_correlations': [(0.8847172825736496, 1.690239250200163e-176),\n",
       "  (0.8844433252787676, 3.0379928720675738e-176),\n",
       "  (0.8848494340360462, 1.2731641597202667e-176),\n",
       "  (0.8843677717008002, 3.570253149279174e-176),\n",
       "  (0.8836896646063283, 1.5128152583785276e-175),\n",
       "  (0.8856842166049749, 2.1086473956538064e-177),\n",
       "  (0.8835388035327452, 2.0833622144966806e-175),\n",
       "  (0.8838613666176682, 1.0504438432585981e-175),\n",
       "  (0.884643970686351, 1.9776691079184798e-176),\n",
       "  (0.8854108770437601, 3.8050704221121494e-177)],\n",
       " 'far_accuracies': [0.48352272727272727,\n",
       "  0.4844318181818182,\n",
       "  0.4838636363636364,\n",
       "  0.4843181818181818,\n",
       "  0.4839772727272727,\n",
       "  0.48363636363636364,\n",
       "  0.48454545454545456,\n",
       "  0.4847727272727273,\n",
       "  0.4838636363636364,\n",
       "  0.48409090909090907],\n",
       " 'far_correlations': [(0.9484928640127243, 9.463052936984235e-265),\n",
       "  (0.9483323815390573, 2.099039933966994e-264),\n",
       "  (0.9484359104002262, 1.2558740621017138e-264),\n",
       "  (0.9486702457367623, 3.9112619634601055e-265),\n",
       "  (0.9483663714703597, 1.7735072438456777e-264),\n",
       "  (0.9483228566212399, 2.2004983659886287e-264),\n",
       "  (0.9482334168274038, 3.4263510849747037e-264),\n",
       "  (0.9485480472959544, 7.191240267457035e-265),\n",
       "  (0.948408362248976, 1.4399561422360128e-264),\n",
       "  (0.9487324135214734, 2.867558171015245e-265)],\n",
       " 'split_accuracies': [0.47306818181818183,\n",
       "  0.47306818181818183,\n",
       "  0.47352272727272726,\n",
       "  0.4727272727272727,\n",
       "  0.4715909090909091,\n",
       "  0.4732954545454545,\n",
       "  0.4727272727272727,\n",
       "  0.47295454545454546,\n",
       "  0.47125,\n",
       "  0.4740909090909091],\n",
       " 'split_correlations': [(0.9041780328750628, 1.8758836709584286e-196),\n",
       "  (0.9049705511607704, 2.3536836238675883e-197),\n",
       "  (0.9052666791523398, 1.078642870171651e-197),\n",
       "  (0.905127184938407, 1.5582786213791937e-197),\n",
       "  (0.9045139750003598, 7.799183247235733e-197),\n",
       "  (0.9050218820187866, 2.056307722754188e-197),\n",
       "  (0.9047700995160637, 3.985666795639101e-197),\n",
       "  (0.9051216394560292, 1.5812168008043474e-197),\n",
       "  (0.9050291823455431, 2.0171709690746114e-197),\n",
       "  (0.904212760791522, 1.7134416860121596e-196)]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../results/pragmatic_listener_assessment_accuracy.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961719739609744"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['aggregate_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9618427943900304"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second time\n",
    "np.mean([cor[0] for cor in results['aggregate_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8845222428859618"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['close_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9485555018949304"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['far_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046507905374798"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor[0] for cor in results['split_correlations']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45305303030303035"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([cor for cor in results['aggregate_accuracies']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46928787878787875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second time\n",
    "np.mean([cor for cor in results['aggregate_accuracies']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9518b6b97569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "_, b = (1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can access classes from parent directory\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monroe_data import MonroeData, MonroeDataEntry, Color # for loading in training data\n",
    "import caption_featurizers                              # for getting caption representations\n",
    "import color_featurizers                                # for getting color representations\n",
    "from experiment import FeatureHandler                   # for combining caption and color features\n",
    "\n",
    "from models import PytorchModel, LiteralSpeaker         # model base that handles training / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = MonroeData(\"../data/csv/train_corpus_monroe.csv\", \"../data/entries/train_entries_monroe.pkl\")\n",
    "dev_data = MonroeData(\"../data/csv/dev_corpus_monroe.csv\", \"../data/entries/dev_entries_monroe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature functions\n",
    "caption_phi = caption_featurizers.CaptionFeaturizer(tokenizer = caption_featurizers.CharacterTokenizer)\n",
    "\n",
    "#    use fourier representation from the hsv space and normalize all hsv values to be between 0 and 1\n",
    "color_phi = color_featurizers.ColorFeaturizer(color_featurizers.color_phi_fourier, \"hsv\", normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker's target is to predict tokens following the SOS token\n",
    "def speaker_target(data_entry):\n",
    "    _, caption_ids = caption_phi.to_string_features(data_entry.caption) # this probably works...\n",
    "    target = caption_ids[1:]\n",
    "    return target\n",
    "# pass in train and dev data, our caption and color feature functions, function for turning an element of our data\n",
    "# (train or dev) into the target, and we only care the target (which is the first color) so we aren't going to mess that up\n",
    "# by randomizing the order of the colors\n",
    "# we aren't going to use the dev data to train the model, but we'll still include it in the feature handler\n",
    "feature_handler = FeatureHandler(train_data, dev_data, caption_phi, color_phi, target_fn=speaker_target, randomized_colors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_handler.train_features()\n",
    "y_train = feature_handler.train_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now would be where we define the model:\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnconditionalCharacterCaptionGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim, speaker_hidden_dim):\n",
    "        super(UnconditionalCharacterCaptionGenerator, self).__init__()\n",
    "        \n",
    "        # for text\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.speaker_lstm = nn.LSTM(embed_dim, speaker_hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(speaker_hidden_dim, vocab_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "    def forward(self, color, captions):\n",
    "        # we get colors because we're using the same framework that the other caption generators use, but \n",
    "        # we don't use them at all because we're an UNCONDITIONAL speaker\n",
    "        \n",
    "        caption_features = self.embed(captions)\n",
    "        \n",
    "        # just use teacher forcing here for now (i.e. don't feed predictions back into network some percentage of the time\n",
    "        #). Not doing this leads to greater instability but is cleaner to implement\n",
    "        hiddens, _ = self.speaker_lstm(caption_features)\n",
    "        outputs = self.linear(hiddens)\n",
    "        output_norm = self.logsoftmax(outputs)\n",
    "        return output_norm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the LiteralSpeaker model to train this, so we can also use it to sample\n",
    "unconditional_character_s0 = LiteralSpeaker(UnconditionalCharacterCaptionGenerator, optimizer=torch.optim.Adam, lr=0.004, num_epochs=5)\n",
    "unconditional_character_s0.init_model(vocab_size=feature_handler.caption_featurizer.caption_indexer.size,\n",
    "                       embed_dim=50, speaker_hidden_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---EPOCH 0---\n",
      "0m 0s (0:0 0.00%) 0.0040\n",
      "0m 5s (0:1000 7.90%) 1.3070\n",
      "0m 12s (0:2000 15.79%) 1.0848\n",
      "0m 18s (0:3000 23.69%) 1.1525\n",
      "0m 26s (0:4000 31.58%) 1.0775\n",
      "0m 33s (0:5000 39.48%) 1.2551\n",
      "0m 39s (0:6000 47.37%) 0.9923\n",
      "0m 45s (0:7000 55.27%) 0.9124\n",
      "0m 51s (0:8000 63.17%) 1.0461\n",
      "0m 57s (0:9000 71.06%) 0.8670\n",
      "1m 3s (0:10000 78.96%) 0.9100\n",
      "1m 9s (0:11000 86.85%) 0.9022\n",
      "1m 15s (0:12000 94.75%) 0.8522\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 1.127891745229562\n",
      "=========================\n",
      "---EPOCH 1---\n",
      "1m 24s (1:0 0.00%) 0.0007\n",
      "1m 29s (1:1000 7.90%) 0.8786\n",
      "1m 35s (1:2000 15.79%) 0.9381\n",
      "1m 43s (1:3000 23.69%) 1.0348\n",
      "1m 50s (1:4000 31.58%) 0.9996\n",
      "1m 58s (1:5000 39.48%) 1.1612\n",
      "2m 5s (1:6000 47.37%) 0.9259\n",
      "2m 11s (1:7000 55.27%) 0.8601\n",
      "2m 18s (1:8000 63.17%) 0.9946\n",
      "2m 24s (1:9000 71.06%) 0.8351\n",
      "2m 30s (1:10000 78.96%) 0.8675\n",
      "2m 35s (1:11000 86.85%) 0.8709\n",
      "2m 40s (1:12000 94.75%) 0.8265\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 1.0845355052848658\n",
      "=========================\n",
      "---EPOCH 2---\n",
      "2m 48s (2:0 0.00%) 0.0007\n",
      "2m 54s (2:1000 7.90%) 0.8513\n",
      "3m 0s (2:2000 15.79%) 0.9192\n",
      "3m 8s (2:3000 23.69%) 1.0201\n",
      "3m 15s (2:4000 31.58%) 0.9853\n",
      "3m 22s (2:5000 39.48%) 1.1348\n",
      "3m 28s (2:6000 47.37%) 0.9164\n",
      "3m 34s (2:7000 55.27%) 0.8428\n",
      "3m 40s (2:8000 63.17%) 0.9753\n",
      "3m 46s (2:9000 71.06%) 0.8281\n",
      "3m 52s (2:10000 78.96%) 0.8579\n",
      "3m 57s (2:11000 86.85%) 0.8597\n",
      "4m 3s (2:12000 94.75%) 0.8185\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 1.0725810062785943\n",
      "=========================\n",
      "---EPOCH 3---\n",
      "4m 11s (3:0 0.00%) 0.0007\n",
      "4m 16s (3:1000 7.90%) 0.8434\n",
      "4m 23s (3:2000 15.79%) 0.8998\n",
      "4m 31s (3:3000 23.69%) 1.0017\n",
      "4m 38s (3:4000 31.58%) 0.9690\n",
      "4m 44s (3:5000 39.48%) 1.1204\n",
      "4m 51s (3:6000 47.37%) 0.9014\n",
      "4m 57s (3:7000 55.27%) 0.8369\n",
      "5m 4s (3:8000 63.17%) 0.9682\n",
      "5m 10s (3:9000 71.06%) 0.8245\n",
      "5m 16s (3:10000 78.96%) 0.8511\n",
      "5m 21s (3:11000 86.85%) 0.8545\n",
      "5m 27s (3:12000 94.75%) 0.8142\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 1.050201769977808\n",
      "=========================\n",
      "---EPOCH 4---\n",
      "5m 35s (4:0 0.00%) 0.0007\n",
      "5m 41s (4:1000 7.90%) 0.8361\n",
      "5m 48s (4:2000 15.79%) 0.8878\n",
      "5m 55s (4:3000 23.69%) 0.9949\n",
      "6m 3s (4:4000 31.58%) 0.9646\n",
      "6m 9s (4:5000 39.48%) 1.1152\n",
      "6m 16s (4:6000 47.37%) 0.9003\n",
      "6m 23s (4:7000 55.27%) 0.8390\n",
      "6m 30s (4:8000 63.17%) 0.9674\n",
      "6m 36s (4:9000 71.06%) 0.8223\n",
      "6m 42s (4:10000 78.96%) 0.8453\n",
      "6m 47s (4:11000 86.85%) 0.8554\n",
      "6m 53s (4:12000 94.75%) 0.8066\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 1.0559827819267908\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "unconditional_character_s0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconditional_character_s0.save_model(\"../model/unconditional_character_literal_speaker.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

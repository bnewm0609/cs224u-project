{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7/3/2019\n",
    "\n",
    "This notebook is for the oracle experiments for predicting what condition the speaker is in. \n",
    "\n",
    "The model developed here takes as input the three colors that make up the context (target first) and then predicts whether the colors are from the close, split, or far condition. The model also takes in captions, because that's what the interface uses, but they are unused. It performs with 0.94 macro-F1 score which is ok, but not wonderful. It should be able to acheive scores closer to 100% because of the clear deliniations between the conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can access classes from parent directory\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monroe_data import MonroeData, MonroeDataEntry, Color # for loading in training data\n",
    "import caption_featurizers                              # for getting caption representations\n",
    "import color_featurizers                                # for getting color representations\n",
    "from experiment import FeatureHandler                   # for combining caption and color features\n",
    "\n",
    "from models import PytorchModel, ConditionPredictor, ColorEncoder  # model base that handles training / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import PytorchModel, ConditionPredictor, ColorEncoder  # model base that handles training / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = MonroeData(\"../data/csv/train_corpus_monroe.csv\", \"../data/entries/train_entries_monroe.pkl\")\n",
    "dev_data = MonroeData(\"../data/csv/dev_corpus_monroe.csv\", \"../data/entries/dev_entries_monroe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature functions\n",
    "caption_phi_character = caption_featurizers.CaptionFeaturizer(tokenizer = caption_featurizers.CharacterTokenizer)\n",
    "\n",
    "# we use a color featurizer because the code was designed to always use both color and text features. These \n",
    "# features will just be ignored in the model code\n",
    "color_phi = color_featurizers.ColorFeaturizer(color_featurizers.color_phi_fourier, \"hsv\", normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a mapping from condition to index from closest to farthest\n",
    "condition_to_idx = {\"close\": 0, \"split\": 1, \"far\":2}\n",
    "\n",
    "# condition predictor's target is to predict what color condition the participants were put in\n",
    "def condition_predictor_target(data_entry):\n",
    "    return condition_to_idx[data_entry.condition]\n",
    "\n",
    "# pass in train and dev data, our caption and color feature functions, function for turning an element of our data\n",
    "# (train or dev) into the target, we don't care about the colors at all, but the feature handler expects them.\n",
    "# We set randomized_colors to false because our target function shouldn't need to take a color index\n",
    "feature_handler = FeatureHandler(train_data, dev_data, caption_phi_character, color_phi, target_fn=condition_predictor_target, randomized_colors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also create an oracle: one that just takes the colors (no captions) in the fourier feature space and\n",
    "# predicts the condition. This should be able to get 100% accuracy. We can use the exact same training data too!\n",
    "\n",
    "class OracleConditionPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, color_in_dim, color_hidden_dim, num_conditions=3):\n",
    "        super(OracleConditionPredictor, self).__init__()\n",
    "        \n",
    "        self.color_encoder = ColorEncoder(color_in_dim, color_hidden_dim)\n",
    "        self.linear = nn.Linear(color_hidden_dim, num_conditions)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, colors, caption):\n",
    "        # caption is ignored because the oracle only accesses colors\n",
    "        color_encs = self.color_encoder(colors)\n",
    "        output_lin = self.linear(color_encs)\n",
    "        outputs = self.logsoftmax(output_lin)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = feature_handler.train_features()\n",
    "y_train = feature_handler.train_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_predictor_oracle = CaptionPredictor(OracleConditionPredictor, optimizer=torch.optim.Adam, lr=0.004, num_epochs=5)\n",
    "condition_predictor_oracle.init_model(color_in_dim=54, color_hidden_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---EPOCH 0---\n",
      "0m 0s (0:0 0.00%) 0.0000\n",
      "0m 2s (0:1000 7.90%) 0.1482\n",
      "0m 4s (0:2000 15.79%) 0.1336\n",
      "0m 6s (0:3000 23.69%) 0.1353\n",
      "0m 8s (0:4000 31.58%) 0.1248\n",
      "0m 11s (0:5000 39.48%) 0.1235\n",
      "0m 13s (0:6000 47.37%) 0.1373\n",
      "0m 15s (0:7000 55.27%) 0.1420\n",
      "0m 17s (0:8000 63.17%) 0.1593\n",
      "0m 19s (0:9000 71.06%) 0.1572\n",
      "0m 21s (0:10000 78.96%) 0.1622\n",
      "0m 23s (0:11000 86.85%) 0.1178\n",
      "0m 26s (0:12000 94.75%) 0.1174\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 0.2010897552172343\n",
      "=========================\n",
      "---EPOCH 1---\n",
      "0m 28s (1:0 0.00%) 0.0000\n",
      "0m 30s (1:1000 7.90%) 0.1285\n",
      "0m 32s (1:2000 15.79%) 0.1239\n",
      "0m 34s (1:3000 23.69%) 0.1416\n",
      "0m 36s (1:4000 31.58%) 0.1136\n",
      "0m 38s (1:5000 39.48%) 0.1292\n",
      "0m 40s (1:6000 47.37%) 0.1310\n",
      "0m 42s (1:7000 55.27%) 0.1249\n",
      "0m 44s (1:8000 63.17%) 0.1309\n",
      "0m 46s (1:9000 71.06%) 0.1526\n",
      "0m 48s (1:10000 78.96%) 0.1621\n",
      "0m 50s (1:11000 86.85%) 0.1372\n",
      "0m 52s (1:12000 94.75%) 0.1170\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 0.18238019279638926\n",
      "=========================\n",
      "---EPOCH 2---\n",
      "0m 54s (2:0 0.00%) 0.0000\n",
      "0m 57s (2:1000 7.90%) 0.1368\n",
      "0m 59s (2:2000 15.79%) 0.1455\n",
      "1m 1s (2:3000 23.69%) 0.1056\n",
      "1m 3s (2:4000 31.58%) 0.1375\n",
      "1m 5s (2:5000 39.48%) 0.1165\n",
      "1m 7s (2:6000 47.37%) 0.1374\n",
      "1m 9s (2:7000 55.27%) 0.0954\n",
      "1m 11s (2:8000 63.17%) 0.1560\n",
      "1m 13s (2:9000 71.06%) 0.1176\n",
      "1m 15s (2:10000 78.96%) 0.0970\n",
      "1m 17s (2:11000 86.85%) 0.1039\n",
      "1m 19s (2:12000 94.75%) 0.1065\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 0.17786314555009206\n",
      "=========================\n",
      "---EPOCH 3---\n",
      "1m 21s (3:0 0.00%) 0.0000\n",
      "1m 24s (3:1000 7.90%) 0.1269\n",
      "1m 26s (3:2000 15.79%) 0.1093\n",
      "1m 28s (3:3000 23.69%) 0.1250\n",
      "1m 30s (3:4000 31.58%) 0.0954\n",
      "1m 32s (3:5000 39.48%) 0.0920\n",
      "1m 34s (3:6000 47.37%) 0.1294\n",
      "1m 36s (3:7000 55.27%) 0.1055\n",
      "1m 38s (3:8000 63.17%) 0.1366\n",
      "1m 41s (3:9000 71.06%) 0.1199\n",
      "1m 43s (3:10000 78.96%) 0.1459\n",
      "1m 45s (3:11000 86.85%) 0.1254\n",
      "1m 47s (3:12000 94.75%) 0.1037\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 0.1875923169006904\n",
      "=========================\n",
      "---EPOCH 4---\n",
      "1m 50s (4:0 0.00%) 0.0000\n",
      "1m 52s (4:1000 7.90%) 0.1214\n",
      "1m 54s (4:2000 15.79%) 0.1173\n",
      "1m 56s (4:3000 23.69%) 0.1346\n",
      "1m 59s (4:4000 31.58%) 0.0932\n",
      "2m 1s (4:5000 39.48%) 0.0886\n",
      "2m 3s (4:6000 47.37%) 0.1124\n",
      "2m 5s (4:7000 55.27%) 0.1047\n",
      "2m 8s (4:8000 63.17%) 0.1543\n",
      "2m 10s (4:9000 71.06%) 0.1189\n",
      "2m 12s (4:10000 78.96%) 0.1117\n",
      "2m 14s (4:11000 86.85%) 0.1065\n",
      "2m 16s (4:12000 94.75%) 0.0901\n",
      "=========================\n",
      "AFTER EPOCH 2999 - AVERAGE VALIDATION LOSS: 0.1840791593591372\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "condition_predictor_oracle.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_predictor_oracle.save_model(\"../model/condition_predictor_oracle10_epochs.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_assess = feature_handler.test_features()\n",
    "y_assess = feature_handler.test_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = condition_predictor_oracle.predict(X_assess)\n",
    "y_hat = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       close       0.98      0.96      0.97      5267\n",
      "       split       0.93      0.90      0.91      5369\n",
      "         far       0.91      0.96      0.93      5034\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     15670\n",
      "   macro avg       0.94      0.94      0.94     15670\n",
      "weighted avg       0.94      0.94      0.94     15670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_hat, y_assess, target_names=['close', 'split', 'far']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = condition_predictor_oracle.predict(X_assess)\n",
    "y_hat = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       close       0.98      0.97      0.98      5223\n",
      "       split       0.93      0.91      0.92      5311\n",
      "         far       0.92      0.95      0.94      5136\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     15670\n",
      "   macro avg       0.94      0.94      0.94     15670\n",
      "weighted avg       0.94      0.94      0.94     15670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_hat, y_assess, target_names=['close', 'split', 'far']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442884492661135"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_assess == y_hat)/len(y_hat) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
